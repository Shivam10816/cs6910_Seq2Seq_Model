{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"id":"_3U0YmtUF9vt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Importing Wandb and Login using Key\n","metadata":{"id":"2tFF0DGLvj3X"}},{"cell_type":"code","source":"%%capture\n!pip install wandb\nimport wandb\nwandb.login(key =\"9c0cf96a5b886197f51883781f17b735b2ac32b1\")","metadata":{"id":"yvQ1-iNkFlwA","execution":{"iopub.status.busy":"2023-05-14T09:20:28.033675Z","iopub.execute_input":"2023-05-14T09:20:28.034348Z","iopub.status.idle":"2023-05-14T09:20:45.051491Z","shell.execute_reply.started":"2023-05-14T09:20:28.034314Z","shell.execute_reply":"2023-05-14T09:20:45.05047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')\n# !wget 'https://drive.google.com/uc?export=download&id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw' -O dataset.zip && unzip dataset.zip","metadata":{"id":"U95DxTfDMKru","execution":{"iopub.status.busy":"2023-05-14T09:20:45.053524Z","iopub.execute_input":"2023-05-14T09:20:45.053893Z","iopub.status.idle":"2023-05-14T09:20:45.059467Z","shell.execute_reply.started":"2023-05-14T09:20:45.05386Z","shell.execute_reply":"2023-05-14T09:20:45.058091Z"},"outputId":"a347a68a-cd2b-4c01-8678-37cfec1339d5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"kKgKFY30wEV_"}},{"cell_type":"code","source":"import plotly.graph_objs as go\nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F","metadata":{"id":"qmUxkf-yNth3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize Seed","metadata":{"id":"EAedH9EWwOXo"}},{"cell_type":"code","source":"#-----------------------Initialize Device---------------------------\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()\nprint(device)\n\n\n#---------------------Start Seed------------------------------------\n\nimport os\ndef seed_everything(seed=1):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nseed_everything()","metadata":{"id":"WitHN9dewVfp","outputId":"462c9900-9afc-4c01-f357-825eba985a95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encode Data","metadata":{"id":"KySyue9jwrYz"}},{"cell_type":"code","source":"\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.char2index = {'#': 0, '$': 1, '^': 2}\n        self.char2count = {'#': 1, '$': 1, '^': 1}\n        self.index2char = {0: '#', 1: '$', 2: '^'}\n        self.n_chars = 3  # Count\n        self.data = {}\n        \n\n    def addWord(self, word):\n        for char in word:\n            self.addChar(char)\n\n    def addChar(self, char):\n        if char not in self.char2index:\n            self.char2index[char] = self.n_chars\n            self.char2count[char] = 1\n            self.index2char[self.n_chars] = char\n            self.n_chars += 1\n        else:\n            self.char2count[char] += 1\n\n\n\n\nclass EncodedData:\n  def __init__(self,lang):\n    \n    #------------------------------------For Kaggle interFace---------------------------------\n\n    self.train_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_train.csv\", header = None)\n    self.val_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_valid.csv\", header = None)\n    self.test_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_test.csv\", header = None)\n\n    #------------------------------------For colab interface-------------------------------------\n\n#     self.train_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_train.csv\", header = None)\n#     self.val_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_valid.csv\", header = None)\n#     self.test_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_test.csv\", header = None)\n\n\n    self.input_lang = Lang('eng')\n    self.output_lang = Lang(lang)\n\n    # add the words to the respective languages\n    for i in range(len(self.train_df)):\n        \n        self.input_lang.addWord(self.train_df[0][i])\n        self.output_lang.addWord(self.train_df[1][i])\n    \n    max_len_1,max_len_2 = self.max_word_lengths(self.train_df)\n    self.train_xE,self.train_yE = self.preprocessing(self.train_df,max_len_1,max_len_2)\n\n    max_len_1,max_len_2 = self.max_word_lengths(self.val_df)\n    self.val_xE,self.val_yE = self.preprocessing(self.val_df,max_len_1,max_len_2)\n\n    max_len_1,max_len_2 = self.max_word_lengths(self.test_df)\n    self.test_xE,self.test_yE = self.preprocessing(self.test_df,max_len_1,max_len_2)\n\n    \n  #-------------------Calculate max length of word in input and output----------\n\n  def max_word_lengths(self,df):\n    max_len_1 = df.iloc[:,0].str.len().max()\n    max_len_2 = df.iloc[:,1].str.len().max()\n    return max_len_1, max_len_2\n\n\n  #-----------------Preprocess on input and output------------------------------\n\n  def preprocessing(self,df,max_len_1,max_len_2):\n    \n    M1 = np.zeros((len(df),max_len_1+1))\n    M2 = np.zeros((len(df),max_len_2+2))\n\n    \n    \n    # ---------------------------Encode column 1-------------------------------\n\n    col1 = df.iloc[:, 0].str.lower().str.split()\n\n    for i in range(len(col1)) :\n      word = col1[i][0]\n      # print(word,\" \" ,word[0],word[1])\n      for j in range(len(word)):\n        char =word[j]\n        if(self.input_lang.char2index.get(char) is not None):\n          M1[i][j]=self.input_lang.char2index.get(char)\n        else:\n          M1[i][j]=1\n    \n    # -----------------------Encode column 2-----------------------------------\n\n    col2 = df.iloc[:, 1].str.lower().str.split()\n\n    for i in range(len(col2)) :\n\n\n      word = col2[i][0]\n  \n      M2[i][0]=2\n      for j in range(len(word)):\n        char =word[j]\n        if(self.output_lang.char2index.get(char) is not None):\n          M2[i][j+1]=self.output_lang.char2index.get(char)\n        else:\n          M2[i][j+1]=1\n\n    \n    return torch.from_numpy(M1),torch.from_numpy(M2)","metadata":{"id":"N3HJM787wp8O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EncoderRNN DecoderRNN ","metadata":{"id":"MxPVr0Vyyg8Y"}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, embedding_size, num_encoders, hidden_size, bidirectional=False, cell='GRU',dropout=0.0):\n        super(EncoderRNN, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_encoders = num_encoders\n        self.bidirectional = bidirectional\n        self.cell = cell\n        self.embedding_size = embedding_size\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n\n        #----------------------RNN----------------------------------------------\n        if self.cell == 'RNN':\n            self.encoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_encoders,\n                                      bidirectional=bidirectional )\n        \n        #----------------------GRU----------------------------------------------\n        elif self.cell == 'GRU':\n            self.encoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_encoders,\n                                      bidirectional=bidirectional)\n\n        #----------------------LSTM---------------------------------------------\n        else:\n            self.encoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_encoders,\n                                       bidirectional=bidirectional )\n            \n    #-------------------------initialize hidden layer---------------------------\n\n    def init_hidden(self, batch_size):\n      \n        #------------------------Number of directions---------------------------\n        num_directions = 2 if self.bidirectional else 1\n\n        #------------------------initialize Hidden Layer------------------------\n        if self.cell == 'LSTM':\n            return (torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device),\n                    torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device))\n        else:\n          return torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device)\n        \n    def forward(self, input_seq):\n        batch_size = input_seq.size(1)\n        \n        # Embedding layer\n        embedded = self.embedding(input_seq.long())\n        \n        embedded = self.dropout(embedded)\n        # Encoder layers\n        encoder_hidden = self.init_hidden(batch_size)\n\n        # print(encoder_hidden.shape)\n        if self.cell == 'LSTM':\n            (encoder_hidden,encoder_cell) = self.init_hidden(batch_size)\n            encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder_rnn(embedded, (encoder_hidden, encoder_cell))\n            encoder_hidden = (encoder_hidden,encoder_cell)\n        else:\n          \n          encoder_outputs, encoder_hidden = self.encoder_rnn(embedded, encoder_hidden)\n        \n        \n        return  encoder_outputs,encoder_hidden\n\n\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, output_size, embedding_size, num_encoders, num_decoders, hidden_size, dropout=0.0, cell='GRU'):\n        super(DecoderRNN, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_encoders = num_encoders\n        self.num_decoders = num_decoders\n        self.cell = cell\n        self.embedding_size = embedding_size\n\n        #------Initialize Dropout , decoder_fc(out),softmax function------------\n        self.dropout = nn.Dropout(dropout)\n        self.decoder_fc = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=-1)\n\n        #-----------------------Initialize Embedding layer----------------------\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        \n\n        if self.cell == 'RNN':\n            self.decoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_decoders)\n        elif self.cell == 'GRU':\n            self.decoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_decoders)\n                                      \n        else :\n            self.decoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_decoders)                      \n                                     \n\n\n    def forward(self, input_seq, hidden):\n        batch_size = input_seq.shape[0]\n        \n\n        \n        decoder_input = input_seq\n\n        decoder_input = decoder_input.unsqueeze(1)\n        \n        # Embedding layer aaplying embedding and dropout\n\n        embedded = self.embedding(decoder_input.long()).view(-1,batch_size,self.embedding_size)\n        # embedded = self.dropout(embedded)\n        decoder_hidden = hidden\n\n        decoder_output , decoder_hidden = self.decoder_rnn(embedded, decoder_hidden)\n       \n        # Project the output to the output size and apply softmax\n\n        decoder_output = self.softmax(self.decoder_fc(decoder_output))\n        \n        # Return the output tensor\n        return decoder_output,decoder_hidden","metadata":{"id":"niDMJ5JTab-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SzyQmkL-ggZF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and Evalution Function for normal decoder","metadata":{"id":"-wT2xoC8aoLL"}},{"cell_type":"code","source":"\n#---------Train Seq2Seq Model--------------------------\n\ndef trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio):\n\n  # input vocabaliry size\n  input_size = data.input_lang.n_chars\n\n  # output vocabaliry size\n  output_size = data.output_lang.n_chars\n\n  # Initialize Encoder , Decoder\n  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n  decoder = DecoderRNN(output_size,embedding_size,num_encoder,num_decoder,hidden_size,dropout,cell_type)\n\n  # Load Data into DataLoader\n  trainData = TensorDataset(data.train_xE, data.train_yE)\n  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n\n  # Initialize Encoder Decoder optimizer and loss function\n  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n\n  # Push encoder and decoder to device\n  encoder.to(device)\n  decoder.to(device)\n\n  seq_len = 20\n  for i in range(epoch):\n  \n    running_loss = 0.0\n    train_correct = 0\n\n    # Set Encoder and Decoder in Train mode\n    encoder.train()\n    decoder.train()\n\n    # forward pass and backtrack for each batch\n\n    for j,(train_x,train_y) in enumerate(trainLoader):\n        loss=0\n\n        seq_len = train_y.shape[1]\n\n        # Load data to device\n        train_x = train_x.to(device)\n        train_y = train_y.to(device)\n        \n        x = train_x.T\n        y = train_y.T\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        # Encoder forward Pass\n        encoder_output, encoder_hidden = encoder(x)\n        \n\n        # handle bidirectional case \n        if bidirectional:\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        decoder_input =(y)[0]\n        \n        # handle layers mismatch\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n\n        # pred_probabilities of batch\n        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n          \n        \n        for k in range(1,y.shape[0]):\n\n          # Decoder Pass\n          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          \n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          \n\n          # teach forcing algorithm\n          if((random.random()<teach_ratio)):\n            decoder_input=(y)[k]\n          else:\n            decoder_input=indices.clone()\n\n        # Decoder forward pass\n        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n        pred_output[-1]=decoder_output\n        \n        \n        \n        # Calculate max probalibity index and load it to device \n        preds = pred_output.argmax(dim=-1)\n        preds = preds.T\n        preds = preds.to(device)\n        \n        # Reshape tensors\n        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n        y = y.reshape(-1)\n\n        # calculate loss\n        loss = loss_fun(pred_output, y.long())\n        \n        # add loss for each batch\n        running_loss += loss.item()\n        \n\n        # Compute the gradients and update the parameters\n        loss.backward()\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n       \n        # Calculate correct words in each batch\n        train_correct += count_exact_matches(preds,train_y)\n\n    # calculate AVg_accuracy and avg_loss      \n    avg_loss = running_loss / (batch_size * len(trainLoader)*seq_len)\n    avg_acc = train_correct/(batch_size*len(trainLoader))\n\n        \n    #calculate validation accuracy and loss for each epoch and log all parameters to waandb\n    val_loss,val_acc ,preds= evaluate(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n    wandb.log({'Train_loss': avg_loss, 'Train_acc': avg_acc*100,'Epoch':i+1,'Val_loss':val_loss,'Val_Acc':val_acc*100})\n  return encoder ,decoder\n\n\n#----------------------------------evaluate on data loss and accuracy-----------\n\ndef evaluate(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n\n    # Set ENCODER and Decoder in evalution Mode\n    encoder.eval()\n    decoder.eval()\n\n    #predictions for whole Dataset\n\n    predicted = None\n    running_loss =0\n    correct=0\n    total=0\n    Data = TensorDataset(X,Y)\n    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n    with torch.no_grad():\n      for j,(xx,yy) in enumerate(Loader):\n        loss=0\n\n        # Push batch to Device\n        xx = xx.to(device)\n        yy = yy.to(device)\n\n        x = xx.transpose(0,1)\n        y = yy.transpose(0,1)\n\n        # Encoder forward pass\n        encoder_output, encoder_hidden = encoder(x)\n        \n        # handle bidirectional case and LSTM cell type\n        if bidirectional:\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor\n          \n        \n        \n        decoder_input =(y)[0]\n        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        pred_output=torch.zeros(y.shape[0],batch_size,output_size)\n          \n\n        # Decoding for one batch\n        for k in range(1,y.shape[0]):\n\n          \n          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden) \n        pred_output[-1]=decoder_output\n\n        preds = pred_output.argmax(dim=-1)\n        preds = preds.T\n        \n        # Concat for whole dataSet\n        if(predicted==None):\n          predicted = preds\n        else:\n          predicted = torch.cat([predicted,preds],dim=0)\n        \n        # Reshape to (batch_size * seq_len, vocab_size) and Load to device\n        pred_output= pred_output.view(-1, pred_output.size(-1))  \n        y = y.reshape(-1)\n\n        pred_output = pred_output.to(device)\n        y =y.to(device)\n\n        # Calculate  Loss\n        loss = loss_fun(pred_output, y.long())\n        running_loss += loss.item()\n        \n        # Calculate correct predictions\n        correct += count_exact_matches(preds,yy)\n        \n    # Loss and Accuracy for Dataset    \n    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size)*Y.shape[1])\n    avg_acc = correct / X.shape[0]\n    \n    return avg_loss , avg_acc , predicted\n\n","metadata":{"id":"9U4LPaXOcE56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supporting functions","metadata":{"id":"L-Po5pDgcOFC"}},{"cell_type":"code","source":"\n# -------------------Count Number of correct words------------------------------\n\ndef count_exact_matches(pred, target):\n    \"\"\"\n    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n    preds: tensor of shape (batch_size, seq_len)\n    y: tensor of shape (batch_size, seq_len)\n    \"\"\"\n    pred = pred[:, 1:-1] # ignore first and last index of each row\n    target = target[:, 1:-1] # ignore first and last index of each row\n    count=0;\n    for i in range(pred.shape[0]):\n      flag = True\n      for j in range(target.shape[1]):\n        if(target[i][j].item()!=0 and target[i][j].item()!=pred[i][j].item()):\n          flag=False\n          break;\n         \n      if(flag):\n        # print(\"---------Correct-----\")\n        # print(pred[i])\n        # print(target[i])\n        count+=1;\n    # print(count)\n    return count\n\n\n        \n\n#------------------------------ Confusion Matrix creation----------------------- \n\ndef confusion_matrix (predicted , target , output_dict_size):\n  '''Create Confusion matrix of shape output_dict_size\n     and return it'''\n  CM = np.zeros((output_dict_size,output_dict_size))\n\n  for i in range(target.shape[0]):\n    for j in range(target.shape[1]):\n       pred = int(predicted[i][j])\n       targ = int(target[i][j])\n       CM[pred][targ]+=1\n  \n  return CM\n\n\n\ndef plot_confusion_matrix(cm,vocab):\n\n\n  # This code will plot Confusion matrix\n\n\n  classes =[]\n\n  for i in range(cm.shape[0]):\n    classes.append(vocab[i])\n\n  print(classes)\n  # Calculate the percentages\n  percentages = (cm / np.sum(cm)) * 100\n\n  # Define the text for each cell\n  cell_text = []\n  for i in range(len(classes)):\n      row_text = []\n      for j in range(len(classes)):\n\n          txt = \"Total \"+f'{cm[i, j]}Per. ({percentages[i, j]:.3f})'\n          if(i==j):\n            txt =\"Correcty Predicted \" +classes[i]+\"\"+txt\n          if(i!=j):\n            txt =\"Predicted \" +classes[j]+\" For \"+classes[i]+\"\"+txt\n          row_text.append(txt)\n      cell_text.append(row_text)\n\n  # Define the trace\n  trace = go.Heatmap(z=percentages,\n                    x=classes,\n                    y=classes,\n                    colorscale='Blues',\n                    colorbar=dict(title='Percentage'),\n                    hovertemplate='%{text}%',\n                    text=cell_text,\n                    )\n\n  # Define the layout\n  layout = go.Layout(title='Confusion Matrix',\n                    xaxis=dict(title='Predicted Character'),\n                    yaxis=dict(title='True Character'),\n                    )\n\n  # Plot the figure\n  fig = go.Figure(data=[trace], layout=layout)\n  return fig\n  #wandb.log({'confusion_matrix': (fig)})\n\n\n# Generate Decoder hidden layer according to number of decoder and decoder and cell_type\n \n\ndef generateDecoderHidden(cell,num_encoder,num_decoder,encoder_hidden):\n    hidden={}\n\n    # ------------For LSTM cell Type--------------------\n\n    if(cell==\"LSTM\"):\n      \n      hx,state = (encoder_hidden)\n\n      # number of encoder > number of decoder\n\n      if(num_encoder>num_decoder):\n        hx = hx[num_encoder-num_decoder:]\n        state = state[num_encoder-num_decoder:]\n      \n      # number of encoder < number of decoder\n\n      elif(num_encoder<num_decoder):\n        top = hx[-1].unsqueeze(0).clone()\n        extra = num_decoder-num_encoder\n        hiddenExtra =top.repeat(extra,1,1)\n        hx =torch.cat((hx,hiddenExtra),dim=0)\n      \n        stop = state[-1].unsqueeze(0).clone()\n        extra = num_decoder-num_encoder\n        stateExtra =top.repeat(extra,1,1)\n        state =torch.cat((state,stateExtra),dim=0)\n\n      hidden=(hx,state)\n\n    # -------------------For Other cell type--------\n\n    else :\n\n      hidden = encoder_hidden\n      \n      # number of encoder > number of decoder\n      if(num_encoder>num_decoder):\n        hidden = encoder_hidden[num_encoder-num_decoder:]\n\n      # number of encoder < number of decoder \n      elif(num_encoder<num_decoder):\n        top = encoder_hidden[-1].unsqueeze(0).clone()\n        extra = num_decoder-num_encoder\n        hiddenExtra =top.repeat(extra,1,1)\n        hidden =torch.cat((encoder_hidden,hiddenExtra),dim=0)\n\n    return hidden\n\n\n\n# test_loss,test_acc,preds = evaluate(data.test_xE,data.test_yE,encoder, decoder, device,data.output_lang.n_chars,len(data.test_xE),bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n\n# print(test_loss , test_acc)  \n","metadata":{"id":"Pwoce_8XKBhY","execution":{"iopub.status.busy":"2023-05-14T09:20:45.061299Z","iopub.execute_input":"2023-05-14T09:20:45.062068Z","iopub.status.idle":"2023-05-14T09:20:48.073777Z","shell.execute_reply.started":"2023-05-14T09:20:45.062035Z","shell.execute_reply":"2023-05-14T09:20:48.072772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attention Decoder","metadata":{"id":"gtY8dMX_yxvW"}},{"cell_type":"code","source":"class AttentionDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding_size , output_size, num_decoder, cell_type, dropout=0.0):\n        super(AttentionDecoderRNN, self).__init__()\n\n        # Define the input size, hidden size, output size, and number of layers\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_decoder\n        self.cell_type = cell_type\n\n        # Define the embedding layer\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n        # Define the attention mechanism\n        self.attention = nn.Linear(hidden_size + embedding_size, hidden_size)\n        self.context_vector = nn.Parameter(torch.zeros(hidden_size))\n        self.energy = nn.Linear(hidden_size * 2, 1)\n        self.softmax = nn.Softmax(dim=0)\n\n        # Define the output layer and relu\n        self.output_layer = nn.Linear(hidden_size, output_size)\n        self.relu = nn.ReLU()\n\n         # Define the dropout layer\n        self.dropout = nn.Dropout(dropout)\n\n        # Define softmax\n        self.logsoftmax = nn.LogSoftmax(dim=-1)\n\n        # Define the RNN layer\n        if cell_type == \"RNN\":\n            self.decoder_rnn = nn.RNN(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n        elif cell_type == \"GRU\":\n            self.decoder_rnn = nn.GRU(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n        elif cell_type == \"LSTM\":\n            self.decoder_rnn = nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n        else:\n            raise ValueError(\"Invalid cell type\")\n\n       \n\n    def forward(self, input, hidden, encoder_outputs):\n\n        # Convert to [1,batch_size] \n        input = input.unsqueeze(0)\n\n        seq_len = encoder_outputs.shape[0]\n        \n        # Embedding layer and Dropout\n        embedding = self.embedding(input.long())\n        \n\n\n\n        cell=None\n        if(self.cell_type==\"LSTM\"):\n          hidden ,cell= hidden \n       \n         hidden_new= hidden.repeat(seq_len, 1,  1)  # repeat along the new dimension\n        \n        \n        \n        #-------------------------Attention Mechanism---------------------------\n        energy = self.relu(self.energy(torch.cat((hidden_new, encoder_outputs), dim=2)))\n        attention = self.softmax(energy)\n        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_outputs)\n        rnn_input = torch.cat((context_vector, embedding), dim=2)\n\n        if(self.cell_type==\"LSTM\"):\n          hidden = (hidden,cell)\n        \n        outputs, decoder_hidden= self.decoder_rnn(rnn_input, hidden)\n       \n        predictions = self.fc(outputs)\n       \n        output = self.logsoftmax(predictions)\n        \n        return output, decoder_hidden ,attention","metadata":{"id":"9deGoZpu4y25","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainining of Attention decoder and evalution for Attention","metadata":{"id":"pY-fsxn31k-v"}},{"cell_type":"code","source":"\ndef trainAttension(data,cell_type=\"RNN\",embedding_size=64,num_encoder=2,num_decoder=2,hidden_size=32,batch_size=16,bidirectional=False,dropout=0.0,beam_width=0,epoch=10,learn_rate=0.001,teach_ratio=0.0):\n  \n  #input/output lang vocabalary size\n  input_size = data.input_lang.n_chars\n  output_size = data.output_lang.n_chars\n\n  # initialize encoder and AttentionDecoder\n  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n  decoder = AttentionDecoderRNN(cell_type=cell_type,dropout=dropout,embedding_size=embedding_size,hidden_size=hidden_size,num_decoder=num_decoder,output_size=output_size)\n\n  # pushData to Loader with given batchSize\n  trainData = TensorDataset(data.train_xE, data.train_yE)\n  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n\n  # Initialize optimizer and Loss Function\n  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n\n  # push Encoder and decoder Device\n  encoder.to(device)\n  decoder.to(device)\n\n  seq_len = 20\n  for i in range(epoch):\n  \n    running_loss = 0.0\n    correct = 0\n\n    # Encoder , Decoder in Train Mode\n    encoder.train()\n    decoder.train()\n    \n    for j,(train_x,train_y) in enumerate(trainLoader):\n        loss=0\n\n        # Seq_len of output\n        seq_len = train_y.shape[1]\n\n        # push batch to device\n        train_x = train_x.to(device)\n        train_y = train_y.to(device)\n\n        # transpose Batch dat\n        x = train_x.transpose(0, 1)\n        y = train_y.transpose(0, 1)\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        # encoder forward pass\n        encoder_output, encoder_hidden = encoder(x)\n        \n\n        # Handle birectional and LSTM case\n        if bidirectional:\n          hidden_size = encoder_output.size(2) // 2\n          forward_output = encoder_output[:, :, :hidden_size]\n          backward_output = encoder_output[:, :, hidden_size:]\n          encoder_output = torch.add(forward_output, backward_output)/2\n\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden , decoder_input tensor\n          \n        \n        \n        decoder_input =(y)[0]\n        \n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n          \n        \n        for k in range(1,y.shape[0]):\n\n          \n          decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n         \n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          \n          if((random.random()<teach_ratio)):\n            decoder_input=(y)[k]\n          else:\n            decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n        pred_output[-1]=decoder_output\n        \n        # get predicted indices (words for batch)\n        preds = pred_output.argmax(dim=-1)\n        preds = preds.T    #[batch_size , seq_len]\n        \n\n        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n        y = y.reshape(-1)\n\n        \n        # compute loss\n        loss = loss_fun(pred_output, y.long())\n        running_loss += loss.item()\n\n        # Compute the gradients and update the parameters\n        loss.backward()\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        # Compute correct matches\n\n        correct += count_exact_matches(preds,train_y)\n       \n    # loss and accuracy for whole data    \n    avg_loss = running_loss / (batch_size * len(trainLoader)*seq_len)\n    avg_acc = correct/(batch_size*(len(trainLoader)))\n    \n\n    running_loss = 0.0\n    correct = 0\n            \n    val_loss,val_acc,preds = evaluateAttension(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n    wandb.log({'Train_loss': avg_loss, 'Train_acc': avg_acc*100,'Epoch':i+1,'Val_loss':val_loss,'Val_Acc':val_acc})\n  return encoder ,decoder\n\n\n\ndef evaluateAttension(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n    \n    # Set encoder decoder in evalution Mode\n    encoder.eval()\n    decoder.eval()\n\n    # Initialize predicted , runningloss , correct ( predictions)\n    predicted=None\n    running_loss =0\n    correct=0\n    \n    # Load data into Loader and initialize loss function\n    Data = TensorDataset(X,Y)\n    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n\n    # Calculate loss for whole data and total correct predictions \n    with torch.no_grad():\n      for j,(xx,yy) in enumerate(Loader):\n        \n        #  push Batch to device\n        x = xx.to(device)\n        y = yy.to(device)\n\n        x = x.transpose(0,1)\n        y = y.transpose(0,1)\n\n        # Encoder forawrd pass\n        encoder_output, encoder_hidden = encoder(x)\n        \n        #handle bidirectional case\n        if bidirectional:\n          hidden_size = encoder_output.size(2) // 2\n          forward_output = encoder_output[:, :, :hidden_size]\n          backward_output = encoder_output[:, :, hidden_size:]\n          encoder_output = torch.add(forward_output, backward_output)/2\n\n          # print(hidden_size)\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor and decoder_input\n        decoder_input =(y)[0]\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        \n        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n        for k in range(1,y.shape[0]):\n\n          \n          decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          \n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output) \n        pred_output[-1]=decoder_output\n       \n        \n        # Get predicted Words\n        preds = pred_output.argmax(dim=-1)\n        preds = preds.T\n\n        if(predicted==None):\n          predicted = preds\n        else:\n          predicted = torch.cat([predicted,preds],dim=0)\n        preds=preds.to(device)\n\n        # Reshape to (batch_size * seq_len, vocab_size)\n        pred_output= pred_output.view(-1, pred_output.size(-1))  \n        y = y.reshape(-1)\n        \n        # calculate loss and correct predictions for batch\n        loss = loss_fun(pred_output, y.long())\n        running_loss += loss.item()\n        correct += count_exact_matches(preds,yy)\n          \n        \n    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size)*Y.shape[1])\n  \n    avg_acc = 100*correct / X.shape[0]\n    \n    return avg_loss , avg_acc , predicted\n    \n# encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n\n  \n","metadata":{"id":"WMP8rrqG10pN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data for language \n","metadata":{"id":"iF0W-_tHOcRU"}},{"cell_type":"code","source":"\ndata = EncodedData(\"hin\")    \n","metadata":{"id":"Fwv002S2J8ie","execution":{"iopub.status.busy":"2023-05-14T09:20:48.076674Z","iopub.execute_input":"2023-05-14T09:20:48.077481Z","iopub.status.idle":"2023-05-14T09:20:51.447467Z","shell.execute_reply.started":"2023-05-14T09:20:48.077444Z","shell.execute_reply":"2023-05-14T09:20:51.446482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Wandb configuration for sweep runs\n","metadata":{"id":"s4eLcOzNgVQI"}},{"cell_type":"code","source":"def wandb_runs(data):\n\n      #-------Wandb configurations--------\n\n    config = {\n        \"project\":\"CS6910_Assignment3_\",\n        \"method\": 'bayes',\n        \"metric\": {\n        'name': 'Val_Acc',\n        'goal': 'maximize'\n        },\n        'parameters' :{\n        \"epoch\": {\"values\":[30]},\n        \"learn_rate\": {\"values\":[0.001]},\n        \"batch_size\": {\"values\": [256,64,32]},\n        \"embedding_size\": {\"values\":[1024,512,256,64]},\n        \"hidden_size\": {\"values\":[ 1024,512,256,64]},\n        \"encoder_layers\": {\"values\":[1]},\n        \"decoder_layers\": {\"values\":[1]},\n        \"cell_type\": {\"values\":[\"RNN\"]},\n        \"bi_directional\":{\"values\":[\"No\"]},\n        \"dropout\":{\"values\":[0.0,0.2,0.3]},\n        \"attention\":{\"values\":[\"Yes\"]},\n        \"teach_ratio\":{\"values\":[0.0,0.2,0.4,0.6]}\n        \n        }\n    }\n\n    #------Train function-----------\n\n    def train_rnn():\n\n      #-----initialize project---------\n\n      \n        wandb.init()\n        \n       \n        # ---- Sweep Name-----\n\n        name='_CT_'+str(wandb.config.cell_type)+\"_BS_\"+str(wandb.config.batch_size)+\"_EPOCH_\"+str(wandb.config.epoch)+\"_ES_\"+str(wandb.config.embedding_size)+\"_HS_\"+str(wandb.config.hidden_size)\n        wandb.run.name = name\n        \n\n        # parameters to pass to functions\n        \n        learn_rate = wandb.config.learn_rate\n        batch_size = wandb.config.batch_size\n        hidden_size = wandb.config.hidden_size\n        embedding_size = wandb.config.embedding_size\n        num_encoder = wandb.config.encoder_layers\n        num_decoder = wandb.config.decoder_layers\n        cell_type = wandb.config.cell_type\n        bidirectional = (wandb.config.bi_directional==\"Yes\")\n        dropout = wandb.config.dropout\n        teach_ratio = wandb.config.teach_ratio\n        epoch = wandb.config.epoch\n        beam_width =0\n        encoder =None\n        decoder = None\n\n\n        if wandb.config.attention == \"Yes\" :\n            \n            encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n        else:\n            \n            encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n        \n        wandb.run.save()\n        wandb.run.finish()\n    sweep_id=wandb.sweep(config,project=\"CS6910_Assignment3__AAtention\")\n    \n\n    # ------Number of experiments we want to run--------\n    \n    wandb.agent(sweep_id,function=train_rnn,count=50)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n#     wandb.agent(sweep_id,function=train_rnn,count=10)\n","metadata":{"id":"QxHRRcegcuMv","execution":{"iopub.status.busy":"2023-05-14T09:20:51.558755Z","iopub.execute_input":"2023-05-14T09:20:51.559322Z","iopub.status.idle":"2023-05-14T09:20:51.573053Z","shell.execute_reply.started":"2023-05-14T09:20:51.559287Z","shell.execute_reply":"2023-05-14T09:20:51.572015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1nRPy10d_ebq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"VkKDIHiUgUwH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Igy33O64F1ay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"q7e__rzOqvHl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"PPTB1O7EFSzT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Wandb sweep runs\n","metadata":{"id":"FBaYBKQNA8hA"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.finish()\nwandb_runs(data)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T09:20:51.57559Z","iopub.execute_input":"2023-05-14T09:20:51.575878Z","iopub.status.idle":"2023-05-14T09:20:51.587193Z","shell.execute_reply.started":"2023-05-14T09:20:51.575854Z","shell.execute_reply":"2023-05-14T09:20:51.586195Z"},"id":"60ANGwbUrJ9s","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"apd_UXYMLUg1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"CecJGVVp3-rJ","execution":{"iopub.status.busy":"2023-05-14T09:20:51.591408Z","iopub.execute_input":"2023-05-14T09:20:51.591804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1rlYhDeUBgGK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Translate prediction to proper words according to dictionary  and save in DataFrame formate (Input , predicted,Actual)\n","metadata":{"id":"oITf1FJKBcw8"}},{"cell_type":"code","source":"def translate_prediction(InDict , input,OutDict,pred,target):\n    \n    '''give input and pred in shape of batch_size*seq_len'''\n\n    pred = pred[:, 1:-1] # ignore first and last index of each row\n    input = input[:, :-1] # ignore  last index of each row\n    target = target[:, 1:-1] # ignore  last index of each row\n    predictions = [] \n    Input = [] \n    Target = []\n    for i in range(pred.shape[0]):\n        \n        stringP=\"\" # Predicted word\n        stringIn=\"\" # Input word\n        stringActu = \"\" # Actual string\n\n        for j in range(pred.shape[1]):\n\n            # Ignore padding\n            if(target[i][j].item()!=0):\n              \n              stringP = stringP + OutDict[pred[i][j].item()]\n              stringActu = stringActu+OutDict[target[i][j].item()]\n                    \n        for j in range(input.shape[1]):\n            \n               if(input[i][j].item()!=0):\n                    \n                    stringIn = stringIn + InDict[input[i][j].item()]   \n\n        # Append words in respective List\n        \n        predictions.append(stringP)\n        Input.append(stringIn)         \n        Target.append(stringActu)   \n\n    # Create a DataFrame\n    df = pd.DataFrame({\"input\": Input, \"predicted\": predictions,\"Actual\":Target})\n\n    return df\n\n            ","metadata":{"id":"UN8EqMnc4Vkw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attention weight heatmap","metadata":{"id":"2GqlGL9ooq5K"}},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport numpy as np\ndef Attension_heatmap(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n    \n    # Assuming you have a tensor named 'data' with shape [num_samples, ...]\n    num_samples = X.shape[0]\n    num_selected_samples = batch_size\n\n    # Generate random permutation of indices\n    random_indices = torch.randperm(num_samples)[:num_selected_samples]\n\n    # Select the corresponding samples from the tensor\n    X = X[random_indices]\n    Y = Y[random_indices]\n\n    # Set encoder decoder in evalution Mode\n    encoder.eval()\n    decoder.eval()\n\n    # Initialize predicted , runningloss , correct ( predictions)\n    attention_weights=None\n    \n    # Load data into Loader and initialize loss function\n   \n    print(X.shape)\n    # Calculate loss for whole data and total correct predictions \n    with torch.no_grad():\n      \n        \n        #  push Batch to device\n        x = X.to(device)\n        y = Y.to(device)\n\n        x = x.transpose(0,1)\n        y = y.transpose(0,1)\n\n        # Encoder forawrd pass\n        encoder_output, encoder_hidden = encoder(x)\n        \n        #handle bidirectional case\n        if bidirectional:\n          hidden_size = encoder_output.size(2) // 2\n          forward_output = encoder_output[:, :, :hidden_size]\n          backward_output = encoder_output[:, :, hidden_size:]\n          encoder_output = torch.add(forward_output, backward_output)/2\n\n          # print(hidden_size)\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor and decoder_input\n        decoder_input =(y)[0]\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        \n        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n        for k in range(1,y.shape[0]):\n\n          \n          decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n        \n          print(attention.shape)\n          if(attention_weights==None):\n            attention_weights=attention\n          else :\n            attention_weights = torch.cat([attention_weights,attention],dim = -1)\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          \n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output) \n        attention_weights = torch.cat([attention_weights,attention],dim = -1)\n       \n        print(attention_weights.shape)\n        # Get predicted Words\n        attention_weights = (attention_weights.cpu()).numpy()\n        attention_weights = attention_weights.transpose(1, 2, 0)\n\n        # Normalize the attention weights across the input sequence axis\n        attention_weights = attention_weights / np.sum(attention_weights, axis=2, keepdims=True)\n        print(attention_weights.shape)\n\n        attention_weights_fixed = np.nan_to_num(attention_weights, nan=0.0000001)\n\n        # Create a 3x3 grid of subplots for heatmaps\n        fig = make_subplots(rows=4, cols=4)\n\n        # Add heatmaps to the grid\n        for i in range(batch_size):\n            heatmap = attention_weights[i]\n            \n            x_label , y_label = [] , []\n\n            for k in range(X.shape[1]):\n              char = data.input_lang.index2char[(X[i][k]).item()]\n              x_label.append(char)\n            \n            for k in range(Y.shape[1]):\n              char = data.output_lang.index2char[(Y[i][k]).item()]\n              y_label.append(char)\n            # Create a heatmap trace\n            heatmap_trace = go.Heatmap(z=heatmap,\n                                      x=y_label,\n                                      y=x_label,\n                                      colorscale='hot',\n                                      reversescale=True,\n                                      showscale=False)\n\n            # Add the heatmap trace to the subplot\n            row = (i // 4) + 1\n            col = (i % 4) + 1\n            fig.add_trace(heatmap_trace, row=row, col=col)\n\n           # Set subplot titles\n            # Set subplot titles\n    \n            fig.update_xaxes(title_text=\"Output Sequence\", row=row, col=col)\n            fig.update_yaxes(title_text=\"Input Sequnece\", row=row, col=col)\n\n            # Update subplot titles\n            fig.update_layout(title=f\"Attention Heatmap Grid\", height=800, width=800)\n\n        # Show the grid of heatmaps\n        wandb.log({\"heatmap \":fig})\n\n        # # Create a 3x3 grid of subplots for heatmaps\n        # fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n\n        # # Plot the attention heatmaps in the grid\n        # for i, ax in enumerate(axes.flatten()):\n        #     heatmap = attention_weights[i]\n        #     ax.imshow(heatmap, cmap='hot', interpolation='nearest')\n        #     x_label , y_label = [] , []\n\n        #     for k in range(X.shape[1]):\n        #       char = data.input_lang.index2char[(X[i][k]).item()]\n        #       x_label.append(char)\n            \n        #     for k in range(Y.shape[1]):\n        #       char = data.output_lang.index2char[(Y[i][k]).item()]\n        #       y_label.append(char)\n        #     ax.set_xticks(np.arange(Y.shape[1]))\n        #     ax.set_yticks(np.arange(X.shape[1]))\n        #     ax.set_xticklabels(y_label)\n        #     ax.set_yticklabels(x_label)\n\n        #     ax.set_title(f'Sample {random_indices[i]}')\n        #     ax.set_xlabel('Decoder Sequence ')\n        #     ax.set_ylabel('Encoder Sequence ')\n\n        # # Adjust spacing\n        # plt.tight_layout()\n\n        # # Log the figure to wandb\n        # wandb.log({\"attention_heatmaps\": wandb.Image(fig)})\n\n        # # Display the figure\n        # plt.show()\n\n        \n    \n    \n   \n","metadata":{"id":"6L0wefltB7uV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For Best run calculate test accuracy and get word to word prediction","metadata":{"id":"F8-5RnN2Cpmp"}},{"cell_type":"code","source":"","metadata":{"id":"JC3PmGiYC0QQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Best_Run(data):\n    \n    config = {\n        \"project\":\"CS6910_Assignment3\",\n        \"method\": 'bayes',\n        \"metric\": {\n        'name': 'Val_acc',\n        'goal': 'maximize'\n        },\n        'parameters' :{\n        \"epoch\": {\"values\":[30]},\n        \"learn_rate\": {\"values\":[0.001]},\n        \"batch_size\": {\"values\": [256]},\n        \"embedding_size\": {\"values\":[ 256]},\n        \"hidden_size\": {\"values\":[1024]},\n        \"encoder_layers\": {\"values\":[1]},\n        \"decoder_layers\": {\"values\":[1]},\n        \"cell_type\": {\"values\":[\"LSTM\"]},\n        \"bi_directional\":{\"values\":[\"Yes\"]},\n        \"dropout\":{\"values\":[0.2]},\n        \"attention\":{\"values\":[\"No\"]},\n        \"teach_ratio\":{\"values\":[0.6]}\n        \n        }\n    }\n    def train_rnn():\n        wandb.init()\n        \n       \n\n        name='_CT_'+str(wandb.config.cell_type)+\"_BS_\"+str(wandb.config.batch_size)+\"_EPOCH_\"+str(wandb.config.epoch)+\"_ES_\"+str(wandb.config.embedding_size)+\"_HS_\"+str(wandb.config.hidden_size)\n        wandb.run.name = name\n        \n\n        \n        \n        learn_rate = wandb.config.learn_rate\n        batch_size = wandb.config.batch_size\n        hidden_size = wandb.config.hidden_size\n        embedding_size = wandb.config.embedding_size\n        num_encoder = wandb.config.encoder_layers\n        num_decoder = wandb.config.decoder_layers\n        cell_type = wandb.config.cell_type\n        bidirectional = (wandb.config.bi_directional==\"Yes\")\n        dropout = wandb.config.dropout\n        teach_ratio = wandb.config.teach_ratio\n        epoch = wandb.config.epoch\n        beam_width =0\n        encoder =None\n        decoder = None\n        test_loss = None\n        test_acc = None\n        preds = None\n\n        if wandb.config.attention == \"Yes\" :\n            \n            encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n            test_loss,test_acc,preds = evaluateAttension(data.test_xE,data.test_yE,encoder, decoder, device,data.output_lang.n_chars,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n            wandb.log({\"test_loss\":test_loss,\"test_acc\":test_acc})\n            Attension_heatmap(data.test_xE,data.test_yE,encoder,decoder,device,data.output_lang.n_chars,16,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n            dataframe = translate_prediction(data.input_lang.index2char,data.test_xE,data.output_lang.index2char,preds,data.test_yE)\n            dataframe.to_csv(\"predictions_Attention.csv\")\n        else:\n            \n            encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n            test_loss,test_acc,preds = evaluate(data.test_xE,data.test_yE,encoder, decoder, device,data.output_lang.n_chars,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n            wandb.log({\"test_loss\":test_loss,\"test_acc\":test_acc*100})\n            dataframe = translate_prediction(data.input_lang.index2char,data.test_xE,data.output_lang.index2char,preds,data.test_yE)\n            dataframe.to_csv(\"predictions_Vannila.csv\")\n        \n            \n            \n\n        \n        \n        \n        \n\n        print(\"confusion matrix start\")\n        CM = confusion_matrix(preds,data.test_yE,data.output_lang.n_chars)\n\n        print(\"confusion matrix done\")\n        fig = plot_confusion_matrix(CM,data.output_lang.index2char)\n        print(\"fig done\")\n        wandb.log({'confusion_matrix': (fig)})\n\n        wandb.run.save()\n        wandb.run.finish()\n    sweep_id=wandb.sweep(config,project=\"CS6910_Assignment3_Best_run\")\n    \n    \n    wandb.agent(sweep_id,function=train_rnn,count=1)\n# wandb.finish()  \n# Best_Run(data)","metadata":{"id":"WFFGOYan5uR6","outputId":"d91f35e6-f247-4500-b1a5-eb48521e64d6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WXri8nq3acPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"FvVi7lmazt52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"XI-xax7_gPf2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"yfSl3VLTC8Up"}},{"cell_type":"code","source":"\n\n# learn_rate = 0.001\n# batch_size = 32\n# hidden_size = 256\n# embedding_size = 256\n# num_encoder = 2\n# num_decoder = 2\n# cell_type = 'LSTM'\n# bidirectional =True\n# dropout = 0.2\n# teach_ratio = 0.5\n# epoch = 30\n# beam_width =0\n# encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n\n  \n","metadata":{"id":"9cR7pPVjML2S","execution":{"iopub.status.busy":"2023-05-14T09:20:51.451027Z","iopub.execute_input":"2023-05-14T09:20:51.451704Z","iopub.status.idle":"2023-05-14T09:20:51.482641Z","shell.execute_reply.started":"2023-05-14T09:20:51.451667Z","shell.execute_reply":"2023-05-14T09:20:51.481762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention= \"No\"\nlearn_rate = 0.001\nbatch_size = 128\nhidden_size = 512\nembedding_size = 512\nnum_encoder = 3\nnum_decoder = 4\ncell_type = 'GRU'\nbidirectional =True\ndropout = 0.5\nteach_ratio = 0.5\nepoch = 20\nbeam_width =0","metadata":{"id":"hRtX90Xy2gzH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoder = None\n# decoder = None\n# wandb.init()\n# if attention == \"Yes\" :\n            \n#     encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n# else:\n\n#     encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n","metadata":{"id":"F-gb1qoV3_vu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \n        \n# wandb.log({\"test_loss\":test_loss,\"test_acc\":test_acc})\n","metadata":{"id":"_5mF33wVQKuh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds = preds.to(device)\n\n# dataframe = translate_prediction(data.input_lang.index2char,data.test_xE,data.output_lang.index2char,preds,data.test_yE)\n# dataframe.to_csv(\"predictions.csv\")","metadata":{"id":"FqjBMkbFR2PL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aOJE5dYriKu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"TQapNbu06s8b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"id":"Se9DFLwy6Gub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aoctb39aiaWn"},"execution_count":null,"outputs":[]}]}