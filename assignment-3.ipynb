{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install wandb\nimport wandb\nwandb.login(key =\"9c0cf96a5b886197f51883781f17b735b2ac32b1\")","metadata":{"id":"yvQ1-iNkFlwA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# !wget 'https://drive.google.com/uc?export=download&id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw' -O dataset.zip && unzip dataset.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U95DxTfDMKru","outputId":"ac57e273-8081-4375-9d64-25df020cdc7d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.char2index = {'#': 0, '$': 1, '^': 2}\n        self.char2count = {'#': 1, '$': 1, '^': 1}\n        self.index2char = {0: '#', 1: '$', 2: '^'}\n        self.n_chars = 3  # Count\n        self.data = {}\n        \n\n    def addWord(self, word):\n        for char in word:\n            self.addChar(char)\n\n    def addChar(self, char):\n        if char not in self.char2index:\n            self.char2index[char] = self.n_chars\n            self.char2count[char] = 1\n            self.index2char[self.n_chars] = char\n            self.n_chars += 1\n        else:\n            self.char2count[char] += 1\n\n\n\nclass EncodedData:\n  def __init__(self,lang):\n    self.train_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_train.csv\", header = None)\n    self.val_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_valid.csv\", header = None)\n    self.test_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_test.csv\", header = None)\n\n    self.input_lang = Lang('eng')\n    self.output_lang = Lang(lang)\n\n    # add the words to the respective languages\n    for i in range(len(self.train_df)):\n        \n        self.input_lang.addWord(self.train_df[0][i])\n        self.output_lang.addWord(self.train_df[1][i])\n    \n    max_len_1,max_len_2 = self.max_word_lengths(self.train_df)\n    self.train_xE,self.train_yE = self.preprocessing(self.train_df,max_len_1,max_len_2)\n\n    max_len_1,max_len_2 = self.max_word_lengths(self.val_df)\n    self.val_xE,self.val_yE = self.preprocessing(self.val_df,max_len_1,max_len_2)\n\n    max_len_1,max_len_2 = self.max_word_lengths(self.test_df)\n    self.test_xE,self.test_yE = self.preprocessing(self.test_df,max_len_1,max_len_2)\n\n    print(type(self.train_xE))\n    \n  def max_word_lengths(self,df):\n    max_len_1 = df.iloc[:,0].str.len().max()\n    max_len_2 = df.iloc[:,1].str.len().max()\n    return max_len_1, max_len_2\n\n\n\n  def preprocessing(self,df,max_len_1,max_len_2):\n    \n    M1 = np.zeros((len(df),max_len_1+1))\n    M2 = np.zeros((len(df),max_len_2+2))\n\n    #print(M2.shape)\n    \n    # Encode column 1\n    col1 = df.iloc[:, 0].str.lower().str.split()\n\n    for i in range(len(col1)) :\n      word = col1[i][0]\n      # print(word,\" \" ,word[0],word[1])\n      for j in range(len(word)):\n        char =word[j]\n        if(self.input_lang.char2index.get(char) is not None):\n          M1[i][j]=self.input_lang.char2index.get(char)\n        else:\n          M1[i][j]=1\n    # print(col1)\n    #encoded_col1 = np.array([encode(words, dict1, max_len_1) for words in col1])\n    \n    # Encode column 2\n    col2 = df.iloc[:, 1].str.lower().str.split()\n    # print((col2[0]))\n    for i in range(len(col2)) :\n      word = col2[i][0]\n      # print(word,\" \" ,word[0],word[1])\n      M2[i][0]=2\n      for j in range(len(word)):\n        char =word[j]\n        if(self.output_lang.char2index.get(char) is not None):\n          M2[i][j+1]=self.output_lang.char2index.get(char)\n        else:\n          M2[i][j+1]=1\n      \n    \n    \n    return torch.from_numpy(M1),torch.from_numpy(M2)\n\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, embedding_size, num_encoders, hidden_size, bidirectional=False, cell='GRU',dropout=0.0):\n        super(EncoderRNN, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_encoders = num_encoders\n        self.bidirectional = bidirectional\n        self.cell = cell\n        self.embedding_size = embedding_size\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n\n        if self.cell == 'RNN':\n            self.encoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_encoders,\n                                      bidirectional=bidirectional )\n        \n        elif self.cell == 'GRU':\n            self.encoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_encoders,\n                                      bidirectional=bidirectional)\n        else:\n            self.encoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_encoders,\n                                       bidirectional=bidirectional )\n    def init_hidden(self, batch_size):\n        num_directions = 2 if self.bidirectional else 1\n        if self.cell == 'LSTM':\n            return (torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device),\n                    torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device))\n        else:\n          return torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device)\n        \n    def forward(self, input_seq):\n        batch_size = input_seq.size(1)\n        \n        # Embedding layer\n        embedded = self.embedding(input_seq.long())\n        \n        embedded = self.dropout(embedded)\n        # Encoder layers\n        encoder_hidden = self.init_hidden(batch_size)\n\n        # print(encoder_hidden.shape)\n        if self.cell == 'LSTM':\n            (encoder_hidden,encoder_cell) = self.init_hidden(batch_size)\n            encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder_rnn(embedded, (encoder_hidden, encoder_cell))\n            encoder_hidden = (encoder_hidden,encoder_cell)\n        else:\n          \n          encoder_outputs, encoder_hidden = self.encoder_rnn(embedded, encoder_hidden)\n        \n        \n        return  encoder_outputs,encoder_hidden\n\n\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, output_size, embedding_size, num_encoders, num_decoders, hidden_size, dropout=0.0, cell='GRU'):\n        super(DecoderRNN, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_encoders = num_encoders\n        self.num_decoders = num_decoders\n        \n        self.cell = cell\n        self.embedding_size = embedding_size\n        self.dropout = nn.Dropout(dropout)\n        self.decoder_fc = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        \n\n        if self.cell == 'RNN':\n            self.decoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_decoders)\n        elif self.cell == 'GRU':\n            self.decoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_decoders)\n                                      \n        else :\n            self.decoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_decoders)                      \n                                     \n\n\n    def forward(self, input_seq, hidden):\n        batch_size = input_seq.shape[0]\n        \n\n        \n        decoder_input = (input_seq)\n\n        decoder_input = decoder_input.unsqueeze(1)\n        \n        # Embedding layer\n        embedded = self.embedding(decoder_input.long()).view(-1,batch_size,self.embedding_size)\n        embedded = self.dropout(embedded)\n        decoder_hidden = hidden\n\n        decoder_output , decoder_hidden = self.decoder_rnn(embedded, decoder_hidden)\n       \n        # Project the output to the output size and apply softmax\n\n        decoder_output = self.softmax(self.decoder_fc(decoder_output))\n        \n        # Return the output tensor\n        return decoder_output,decoder_hidden\n\ndef count_exact_matches(pred, target):\n    \"\"\"\n    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n    preds: tensor of shape (batch_size, seq_len)\n    y: tensor of shape (batch_size, seq_len)\n    \"\"\"\n    pred = pred[:, 1:-1] # ignore first and last index of each row\n    target = target[:, 1:-1] # ignore first and last index of each row\n    count=0;\n    for i in range(pred.shape[0]):\n      flag = True\n      for j in range(target.shape[1]):\n        if(target[i][j]!=0 and target[i][j]!=pred[i][j]):\n          flag=False\n          break;\n         \n      if(flag):\n        count+=1;\n    \n    return count\n\ndef evaluate(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n    encoder.eval()\n    decoder.eval()\n\n\n    running_loss =0\n    correct=0\n    total=0\n    Data = TensorDataset(X,Y)\n    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n    with torch.no_grad():\n      for j,(x,y) in enumerate(Loader):\n        loss=0\n\n        x = x.to(device)\n        y = y.to(device)\n\n        x = x.transpose(0,1)\n        y = y.transpose(0,1)\n        encoder_output, encoder_hidden = encoder(x)\n        \n        if bidirectional:\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor\n          \n        \n        \n        decoder_input =(y)[0]\n        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        pred_output=torch.zeros(y.shape[0],batch_size,output_size)\n          \n\n        for k in range(1,y.shape[0]):\n\n          \n          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          \n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n        pred_output[-1]=decoder_output\n        # print(pred_output.shape)\n        # print(train_y.shape)\n        \n        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n        y = y.reshape(-1)\n\n        pred_output = pred_output.to(device)\n        y =y.to(device)\n\n        loss = loss_fun(pred_output, y.long())\n        running_loss += loss.item()\n\n        # Compute the gradients and update the parameters\n        \n\n        # Compute the accuracy\n        preds = torch.argmax(pred_output, dim=1)\n\n        preds = preds.reshape(batch_size,-1)\n        y = y.reshape(batch_size,-1)\n        \n        # print(\"------------------Iter next--------------\")\n        # print(preds[:][0])\n        # print(train_y[0])\n        \n        # print(\"-------------------------PRED----------------------\")\n        # print(preds)\n        # print(\"-------------------------Train---------------------\")\n        # print(train_y)\n        correct += count_exact_matches(preds,y)\n          # Print the training progress\n          \n    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size))\n  \n    avg_acc = correct / X.shape[0]\n    \n    return avg_loss , avg_acc\n\n            \n   \n \n\ndef generateDecoderHidden(cell,num_encoder,num_decoder,encoder_hidden):\n    hidden={}\n    if(cell==\"LSTM\"):\n      \n      hx,state = (encoder_hidden)\n      if(num_encoder>num_decoder):\n        hx = hx[num_encoder-num_decoder:]\n        state = state[num_encoder-num_decoder:]\n      elif(num_encoder<num_decoder):\n        top = hx[-1].unsqueeze(0).clone()\n        extra = num_decoder-num_encoder\n        hiddenExtra =top.repeat(extra,1,1)\n        hx =torch.cat((hx,hiddenExtra),dim=0)\n      \n        stop = state[-1].unsqueeze(0).clone()\n        extra = num_decoder-num_encoder\n        stateExtra =top.repeat(extra,1,1)\n        state =torch.cat((state,stateExtra),dim=0)\n\n      hidden=(hx,state)\n    else :\n\n      hidden = encoder_hidden\n          \n      if(num_encoder>num_decoder):\n        hidden = encoder_hidden[num_encoder-num_decoder:]\n        \n      elif(num_encoder<num_decoder):\n        top = encoder_hidden[-1].unsqueeze(0).clone()\n        extra = num_decoder-num_encoder\n        hiddenExtra =top.repeat(extra,1,1)\n        hidden =torch.cat((encoder_hidden,hiddenExtra),dim=0)\n    return hidden\n\n\n\n\n","metadata":{"id":"Pwoce_8XKBhY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"id":"9deGoZpu4y25","colab":{"base_uri":"https://localhost:8080/"},"outputId":"146fe3a6-7d95-4f58-9ea6-65e6c74feba0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get encoded data of perticular language\n\ndata = EncodedData(\"hin\")    \n\nfrom torch.utils.data import TensorDataset\n\n\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fwv002S2J8ie","outputId":"674bdef6-cecf-448d-ffee-fe1c71ffffb5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"q7e__rzOqvHl","colab":{"base_uri":"https://localhost:8080/","height":220},"outputId":"6780c193-b373-4ee0-ef37-a47a7b9f6650","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn_rate = 0.001\nbatch_size = 16\nhidden_size = 128\nembedding_size = 128\nnum_encoder = 3\nnum_decoder = 3\ncell_type = 'RNN'\nbidirectional =True\ndropout = 0.3\nteach_ratio = 0.5\nepochs = 10\n","metadata":{"id":"PPTB1O7EFSzT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef trainRNNandGRU(data,cell_type=\"RNN\",embedding_size=64,num_encoder=2,num_decoders=2,hidden_size=32,batch_size=16,bidirectional=False,dropout=0.0,beam_width=0,epoch=10,learn_rate=0.001,teacher_ratio=0.0):\n  input_size = data.input_lang.n_chars\n  output_size = data.output_lang.n_chars\n  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n  decoder = DecoderRNN(output_size,embedding_size,num_encoder,num_decoder,hidden_size,dropout,cell_type)\n\n  trainData = TensorDataset(data.train_xE, data.train_yE)\n  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n\n\n\n  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n\n  encoder.to(device)\n  decoder.to(device)\n\n  for i in range(epochs):\n  \n    running_loss = 0.0\n    train_correct = 0\n\n    encoder.train()\n    decoder.train()\n\n    for j,(train_x,train_y) in enumerate(trainLoader):\n        loss=0\n        train_x = train_x.to(device)\n        train_y = train_y.to(device)\n\n        train_x = train_x.transpose(0, 1)\n        train_y = train_y.transpose(0, 1)\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_output, encoder_hidden = encoder(train_x)\n        \n        # print(encoder_hidden.shape)\n        # # lets move to the decoder\n        # if(bidirectional):\n        #     split_tensor= torch.split(encoder_output, hidden_size, dim=-1)\n        #     encoder_output=torch.add(split_tensor[0],split_tensor[1])/2\n        \n\n        \n        if bidirectional:\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor\n        \n        # Compute the loss and accuracy\n        \n        decoder_input =(train_y)[0]\n        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        pred_output=torch.zeros(train_y.shape[0],batch_size,output_size)\n          \n        \n        for k in range(1,train_y.shape[0]):\n\n          \n          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          # print(indices)\n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          \n          if((random.random()<teach_ratio)):\n            decoder_input=(train_y)[k]\n          else:\n            decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n          \n        pred_output[-1]=decoder_output\n        \n\n        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n        train_y = train_y.reshape(-1)\n\n        pred_output = pred_output.to(device)\n        train_y = train_y.to(device)\n        loss = loss_fun(pred_output, train_y.long())\n        \n        running_loss += loss.item()\n\n        # Compute the gradients and update the parameters\n        loss.backward()\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        # Compute the accuracy\n        # print(pred_output.shape)\n        preds = torch.argmax(pred_output, dim=1)\n        \n        preds = preds.reshape(batch_size,-1)\n        train_y = train_y.reshape(batch_size,-1)\n        \n        \n        train_correct += count_exact_matches(preds,train_y)\n       \n        \n    avg_loss = running_loss / (batch_size * (len(trainLoader)))\n    avg_acc = train_correct/(batch_size*(len(trainLoader)))\n    \n#     print('Epoch [{}/{}], Step [{}/{}], Train_Loss: {:.4f}, Accuracy :{:.4f}'\n#           .format(i+1, epochs, j+1, len(trainLoader), avg_loss,avg_acc*100))\n    # evaluate(data.val_xE,data.val_yE,encoder,decoder,device,output_size,batch_size,cell_type)\n    \n            \n    val_loss,val_acc = evaluate(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n#     print(\"val_loss:-\",val_loss,\"val_acc :-\",val_acc)\n    wandb.log({'Train_loss': avg_loss, 'Train_acc': avg_acc*100,'Epoch':i+1,'Val_loss':val_loss,'Val_Acc':val_acc})\n  return encoder ,decoder\n\n# learn_rate = 0.01\n# batch_size = 64\n# hidden_size = 16\n# embedding_size = 64\n# num_encoder = 4\n# num_decoder = 2\n# cell_type = 'RNN'\n# bidirectional =True\n# dropout = 0.2\n# teach_ratio = 0.7\n# epochs = 10\n# beam_width =0\n# encoder,decoder=trainRNNandGRU(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n\n  \n","metadata":{"id":"9cR7pPVjML2S","colab":{"base_uri":"https://localhost:8080/","height":924},"outputId":"9bc42fa1-db1d-4cfd-c725-ef47743df32c","trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\nwandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"aVkoOG63MNSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"h1FSM2NTLCeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding_size , output_size, num_decoder, cell_type, dropout=0.0):\n        super(AttentionDecoderRNN, self).__init__()\n\n        # Define the input size, hidden size, output size, and number of layers\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_decoder\n        self.cell_type = cell_type\n        # Define the embedding layer\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        self.fc = nn.Linear(hidden_size, output_size)\n        # Define the attention mechanism\n        self.attention = nn.Linear(hidden_size + embedding_size, hidden_size)\n        self.context_vector = nn.Parameter(torch.zeros(hidden_size))\n        self.energy = nn.Linear(hidden_size * 2, 1)\n        self.softmax = nn.Softmax(dim=0)\n        # Define the output layer\n        self.output_layer = nn.Linear(hidden_size, output_size)\n        \n        self.relu = nn.ReLU()\n        # Define the RNN layer\n        if cell_type == \"RNN\":\n            self.decoder_rnn = nn.RNN(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n        elif cell_type == \"GRU\":\n            self.decoder_rnn = nn.GRU(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n        elif cell_type == \"LSTM\":\n            self.decoder_rnn = nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n        else:\n            raise ValueError(\"Invalid cell type\")\n\n        # Define the dropout layer\n        self.dropout = nn.Dropout(dropout)\n\n        # Define softmax\n        self.logsoftmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden, encoder_outputs):\n        # Compute the attention \n        input = input.unsqueeze(0)\n\n        seq_len = encoder_outputs.shape[0]\n\n        embedding = self.embedding(input.long())\n        embedding = self.dropout(embedding)\n\n\n\n        cell={}\n        if(self.cell_type==\"LSTM\"):\n          hidden ,cell= hidden \n       \n        hidden_row = hidden[0].unsqueeze(0)  # add a new dimension\n        hidden_new= hidden_row.repeat(seq_len-self.num_layers, 1,  1)  # repeat along the new dimension\n        # hidden = hidden.view(seq_len, batch_size, -1)  # reshape to (seq_len, batch_size, hidden_size)\n        hidden_cat = torch.cat([hidden, hidden_new], dim=0)\n        \n        energy = self.relu(self.energy(torch.cat((hidden_cat, encoder_outputs), dim=2)))\n        # print(energy.shape)\n\n        attention = self.softmax(energy)\n        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_outputs)\n        rnn_input = torch.cat((context_vector, embedding), dim=2)\n\n\n        if(self.cell_type==\"LSTM\"):\n          hidden = (hidden,cell)\n        \n\n        outputs, decoder_hidden= self.decoder_rnn(rnn_input, hidden)\n        # print(outputs.shape)\n        predictions = self.fc(outputs)\n        # print(predictions.shape)\n        output = self.logsoftmax(predictions)\n        \n        return output, decoder_hidden\n","metadata":{"id":"22fmCgJ59DO2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef trainAttension(data,cell_type=\"RNN\",embedding_size=64,num_encoder=2,num_decoders=2,hidden_size=32,batch_size=16,bidirectional=False,dropout=0.0,beam_width=0,epoch=10,learn_rate=0.001,teacher_ratio=0.0):\n  input_size = data.input_lang.n_chars\n  output_size = data.output_lang.n_chars\n  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n  decoder = AttentionDecoderRNN(cell_type=cell_type,dropout=dropout,embedding_size=embedding_size,hidden_size=hidden_size,num_decoder=num_decoder,output_size=output_size)\n\n  trainData = TensorDataset(data.train_xE, data.train_yE)\n  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n\n\n\n  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n\n  encoder.to(device)\n  decoder.to(device)\n\n  for i in range(epochs):\n  \n    running_loss = 0.0\n    correct = 0\n\n    encoder.train()\n    decoder.train()\n\n    for j,(train_x,train_y) in enumerate(trainLoader):\n        loss=0\n        train_x = train_x.to(device)\n        train_y = train_y.to(device)\n\n        train_x = train_x.transpose(0, 1)\n        train_y = train_y.transpose(0, 1)\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_output, encoder_hidden = encoder(train_x)\n        \n        # print(encoder_output.shape)\n        # # lets move to the decoder\n        # if(bidirectional):\n        #     split_tensor= torch.split(encoder_output, hidden_size, dim=-1)\n        #     encoder_output=torch.add(split_tensor[0],split_tensor[1])/2\n        \n\n        \n        if bidirectional:\n          hidden_size = encoder_output.size(2) // 2\n          forward_output = encoder_output[:, :, :hidden_size]\n          backward_output = encoder_output[:, :, hidden_size:]\n          encoder_output = torch.add(forward_output, backward_output)/2\n\n          \n        \n          \n          # print(hidden_size)\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor\n          \n        # Compute the loss and accuracy\n        \n        decoder_input =(train_y)[0]\n        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        pred_output=torch.zeros(train_y.shape[0],batch_size,output_size)\n          \n        \n        for k in range(1,train_y.shape[0]):\n\n          \n          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          # print(indices)\n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          \n          if((random.random()<teach_ratio)):\n            decoder_input=(train_y)[k]\n          else:\n            decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n        pred_output[-1]=decoder_output\n        \n\n        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n        train_y = train_y.reshape(-1)\n\n        pred_output = pred_output.to(device)\n        train_y = train_y.to(device)\n        loss = loss_fun(pred_output, train_y.long())\n        \n        running_loss += loss.item()\n\n        # Compute the gradients and update the parameters\n        loss.backward()\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        # Compute the accuracy\n        # print(pred_output.shape)\n        preds = torch.argmax(pred_output, dim=1)\n\n        \n        preds = preds.reshape(batch_size,-1)\n        train_y = train_y.reshape(batch_size,-1)\n        \n        \n        correct += count_exact_matches(preds,train_y)\n        # print(\"------------------Iter next--------------\")\n        # print(preds[:][0])\n        # print(train_y[0])\n        # print(preds.shape)\n        # print(train_y.shape)\n        # print(\"-------------------------PRED----------------------\")\n        # print(preds)\n        # print(\"-------------------------Train---------------------\")\n        # print(train_y)\n        \n        # Print the training progress\n        \n    avg_loss = running_loss / (batch_size * (len(trainLoader)))\n    avg_acc = correct/(batch_size*(len(trainLoader)))\n#     print('Epoch [{}/{}], Step [{}/{}], Train_Loss: {:.4f}, Accuracy :{:.4f}'\n#           .format(i+1, epochs, j+1, len(trainLoader), avg_loss,avg_acc*100))\n#     # evaluate(data.val_xE,data.val_yE,encoder,decoder,device,output_size,batch_size,cell_type)\n    running_loss = 0.0\n    correct = 0\n            \n    val_loss,val_acc = evaluateAttension(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n    wandb.log({'Train_loss': avg_loss, 'Train_acc': avg_acc*100,'Epoch':i+1,'Val_loss':val_loss,'Val_Acc':val_acc})\n  return encoder ,decoder\n\n\ndef evaluateAttension(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n    encoder.eval()\n    decoder.eval()\n\n\n    running_loss =0\n    correct=0\n    total=0\n    Data = TensorDataset(X,Y)\n    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n    with torch.no_grad():\n      for j,(x,y) in enumerate(Loader):\n        loss=0\n\n        x = x.to(device)\n        y = y.to(device)\n\n        x = x.transpose(0,1)\n        y = y.transpose(0,1)\n        encoder_output, encoder_hidden = encoder(x)\n        \n        if bidirectional:\n          hidden_size = encoder_output.size(2) // 2\n          forward_output = encoder_output[:, :, :hidden_size]\n          backward_output = encoder_output[:, :, hidden_size:]\n          encoder_output = torch.add(forward_output, backward_output)/2\n\n          # print(hidden_size)\n          if(cell_type==\"LSTM\"):\n            hidden,state = encoder_hidden\n            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n            hidden=torch.add(hidden[0],hidden[1])/2\n\n            state = state.resize(2,num_encoder,batch_size,hidden_size)\n            state=torch.add(state[0],state[1])/2\n            encoder_hidden =(hidden,state)\n\n          else:\n            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n\n        # Initialize the decoder_hidden tensor\n          \n        \n        \n        decoder_input =(y)[0]\n        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n        \n        pred_output=torch.zeros(y.shape[0],batch_size,output_size)\n          \n\n        for k in range(1,y.shape[0]):\n\n          \n          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n          pred_output[k-1]=decoder_output\n\n          # Get the index of the maximum probability in each row\n          max_probs, indices = torch.max(decoder_output, dim=2)\n\n          \n          # Reshape the indices tensor to (batch_size,) for easier indexing\n          indices = indices.view(batch_size)\n          decoder_input=indices.clone()\n\n        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden,encoder_output)\n          \n        pred_output[-1]=decoder_output\n        # print(pred_output.shape)\n        # print(train_y.shape)\n        \n        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n        y = y.reshape(-1)\n\n        pred_output = pred_output.to(device)\n        y =y.to(device)\n\n        loss = loss_fun(pred_output, y.long())\n        running_loss += loss.item()\n\n        # Compute the gradients and update the parameters\n        \n\n        # Compute the accuracy\n        preds = torch.argmax(pred_output, dim=1)\n\n        preds = preds.reshape(batch_size,-1)\n        y = y.reshape(batch_size,-1)\n        \n        # print(\"------------------Iter next--------------\")\n        # print(preds[:][0])\n        # print(train_y[0])\n        \n        # print(\"-------------------------PRED----------------------\")\n        # print(preds)\n        # print(\"-------------------------Train---------------------\")\n        # print(train_y)\n        correct += count_exact_matches(preds,y)\n          # Print the training progress\n          \n    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size))\n  \n    avg_acc = 100*correct / X.shape[0]\n    \n    return avg_loss , avg_acc\n    \n# encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n\n  \n","metadata":{"id":"YPOcnDlRYDRZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"96e49371-4665-4df1-c798-fae41ae20903","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"x8bNxVuRa6ao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wandb_runs(data):\n    \n    config = {\n        \"project\":\"CS6910_Assignment3\",\n        \"method\": 'bayes',\n        \"metric\": {\n        'name': 'acc',\n        'goal': 'maximize'\n        },\n        'parameters' :{\n        \"epochs\": {\"values\":[5,10,20]},\n        \"learn_rate\": {\"values\":[0.01,0.001,0.0001]},\n        \"batch_size\": {\"values\": [64,128,256]},\n        \"embedding_size\": {\"values\":[16, 32, 64, 256, 512]},\n        \"hidden_size\": {\"values\":[16, 32, 64, 256, 512]},\n        \"encoder_layers\": {\"values\":[2,3,4]},\n        \"decoder_layers\": {\"values\":[2,3,4]},\n        \"cell_type\": {\"values\":[\"RNN\",\"LSTM\",\"GRU\"]},\n        \"bi_directional\":{\"values\":[\"Yes\",\"No\"]},\n        \"dropout\":{\"values\":[0.1,0.2,0.5]},\n        \"attention\":{\"values\":[\"Yes\",\"No\"]},\n        \"teach_ratio\":{\"values\":[0.2,0.5,0.7]}\n        \n        }\n    }\n    def train_rnn():\n        wandb.init()\n        \n       \n\n        name='_CT_'+str(wandb.config.cell_type)+\"_BS_\"+str(wandb.config.batch_size)+\"_EPOCH_\"+str(wandb.config.epochs)+\"_ES_\"+str(wandb.config.embedding_size)+\"_HS_\"+str(wandb.config.hidden_size)\n        wandb.run.name = name\n        \n\n        \n        \n        learn_rate = wandb.config.learn_rate\n        batch_size = wandb.config.batch_size\n        hidden_size = wandb.config.hidden_size\n        embedding_size = wandb.config.embedding_size\n        num_encoder = wandb.config.encoder_layers\n        num_decoder = wandb.config.decoder_layers\n        cell_type = wandb.config.cell_type\n        bidirectional = (wandb.config.bi_directional==\"Yes\")\n        dropout = wandb.config.dropout\n        teach_ratio = wandb.config.teach_ratio\n        epochs = wandb.config.epochs\n        beam_width =0\n        if wandb.config.attention == \"Yes\" :\n            \n            encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n        else:\n            \n            encoder,decoder=trainRNNandGRU(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n\n          \n        \n        wandb.run.save()\n        wandb.run.finish()\n    sweep_id=wandb.sweep(config,project=\"CS6910_Assignment3\")\n    \n    \n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n    wandb.agent(sweep_id,function=train_rnn,count=10)\n","metadata":{"id":"QxHRRcegcuMv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb_runs(data)","metadata":{"id":"CecJGVVp3-rJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention= Yes\nbatch_size=64\nbi_directional=False\ncell_type='RNN'\nnum_decoders4\ndropout= 0.5\nembedding_size= 256\nnum_encoders= 3\nwandb: \tepochs: 10\nwandb: \thidden_size: 256\nwandb: \tlearn_rate: 0.0001\nwandb: \tteach_ratio: 0.2","metadata":{"id":"XI-xax7_gPf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention= \"Yes\"\nlearn_rate = 0.0001\nbatch_size = 64\nhidden_size = 256\nembedding_size = 256\nnum_encoder = 3\nnum_decoder = 4\ncell_type = 'RNN'\nbidirectional =False\ndropout = 0.5\nteach_ratio = 0.2\nepochs = 10\nbeam_width =0","metadata":{"id":"hRtX90Xy2gzH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if attention == \"Yes\" :\n            \n#     encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n# else:\n\n#     encoder,decoder=trainRNNandGRU(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n","metadata":{"id":"F-gb1qoV3_vu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_prediction()","metadata":{"id":"UN8EqMnc4Vkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WFFGOYan5uR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"FvVi7lmazt52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aOJE5dYriKu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"TQapNbu06s8b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"id":"Se9DFLwy6Gub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aoctb39aiaWn"},"execution_count":null,"outputs":[]}]}