{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16d5-SjPO8eM9xVBs72Lf4HY2McPKRjcT",
      "authorship_tag": "ABX9TyOA/biocvi8Kb9t0TI4RggI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivam10816/cs6910_assignment3/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yvQ1-iNkFlwA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U95DxTfDMKru",
        "outputId": "72f3ebc0-1723-4bff-df65-56e94fb871f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2index = {'#': 0, '$': 1, '^': 2}\n",
        "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
        "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
        "        self.n_chars = 3  # Count\n",
        "        self.data = {}\n",
        "        \n",
        "\n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            self.addChar(char)\n",
        "\n",
        "    def addChar(self, char):\n",
        "        if char not in self.char2index:\n",
        "            self.char2index[char] = self.n_chars\n",
        "            self.char2count[char] = 1\n",
        "            self.index2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "        else:\n",
        "            self.char2count[char] += 1\n",
        "\n",
        "\n",
        "\n",
        "class EncodedData:\n",
        "  def __init__(self,lang):\n",
        "    self.train_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_train.csv\", header = None)\n",
        "    self.val_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_valid.csv\", header = None)\n",
        "    self.test_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_test.csv\", header = None)\n",
        "\n",
        "    self.input_lang = Lang('eng')\n",
        "    self.output_lang = Lang(lang)\n",
        "\n",
        "    # add the words to the respective languages\n",
        "    for i in range(len(self.train_df)):\n",
        "        \n",
        "        self.input_lang.addWord(self.train_df[0][i])\n",
        "        self.output_lang.addWord(self.train_df[1][i])\n",
        "    \n",
        "    max_len_1,max_len_2 = self.max_word_lengths(self.train_df)\n",
        "    self.train_xE,self.train_yE = self.preprocessing(self.train_df,max_len_1,max_len_2)\n",
        "\n",
        "    max_len_1,max_len_2 = self.max_word_lengths(self.val_df)\n",
        "    self.val_xE,self.val_yE = self.preprocessing(self.val_df,max_len_1,max_len_2)\n",
        "\n",
        "    max_len_1,max_len_2 = self.max_word_lengths(self.val_df)\n",
        "    self.val_xE,self.val_yE = self.preprocessing(self.val_df,max_len_1,max_len_2)\n",
        "\n",
        "    print(type(self.train_xE))\n",
        "    \n",
        "  def max_word_lengths(self,df):\n",
        "    max_len_1 = df.iloc[:,0].str.len().max()\n",
        "    max_len_2 = df.iloc[:,1].str.len().max()\n",
        "    return max_len_1, max_len_2\n",
        "\n",
        "\n",
        "\n",
        "  def preprocessing(self,df,max_len_1,max_len_2):\n",
        "    \n",
        "    M1 = np.zeros((len(df),max_len_1+1))\n",
        "    M2 = np.zeros((len(df),max_len_2+2))\n",
        "\n",
        "    #print(M2.shape)\n",
        "    \n",
        "    # Encode column 1\n",
        "    col1 = df.iloc[:, 0].str.lower().str.split()\n",
        "\n",
        "    for i in range(len(col1)) :\n",
        "      word = col1[i][0]\n",
        "      # print(word,\" \" ,word[0],word[1])\n",
        "      for j in range(len(word)):\n",
        "        char =word[j]\n",
        "        if(self.input_lang.char2index.get(char) is not None):\n",
        "          M1[i][j]=self.input_lang.char2index.get(char)\n",
        "        else:\n",
        "          M1[i][j]=1\n",
        "    # print(col1)\n",
        "    #encoded_col1 = np.array([encode(words, dict1, max_len_1) for words in col1])\n",
        "    \n",
        "    # Encode column 2\n",
        "    col2 = df.iloc[:, 1].str.lower().str.split()\n",
        "    # print((col2[0]))\n",
        "    for i in range(len(col2)) :\n",
        "      word = col2[i][0]\n",
        "      # print(word,\" \" ,word[0],word[1])\n",
        "      M2[i][0]=2\n",
        "      for j in range(len(word)):\n",
        "        char =word[j]\n",
        "        if(self.output_lang.char2index.get(char) is not None):\n",
        "          M2[i][j+1]=self.output_lang.char2index.get(char)\n",
        "        else:\n",
        "          M2[i][j+1]=1\n",
        "      \n",
        "    \n",
        "    \n",
        "    return torch.from_numpy(M1),torch.from_numpy(M2)\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, num_encoders, hidden_size, bidirectional=False, cell='GRU',dropout=0.0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoders = num_encoders\n",
        "        self.bidirectional = bidirectional\n",
        "        self.cell = cell\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        \n",
        "        if self.cell == 'RNN':\n",
        "            self.encoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_encoders,\n",
        "                                      bidirectional=bidirectional,dropout=dropout )\n",
        "        elif self.cell == 'LSTM':\n",
        "            self.encoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_encoders,\n",
        "                                       bidirectional=bidirectional,dropout=dropout )\n",
        "        elif self.cell == 'GRU':\n",
        "            self.encoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_encoders,\n",
        "                                      bidirectional=bidirectional, dropout=dropout)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        if self.cell == 'LSTM':\n",
        "            return (torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device),\n",
        "                    torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device))\n",
        "        else:\n",
        "            return torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device)\n",
        "        \n",
        "    def forward(self, input_seq):\n",
        "        batch_size = input_seq.size(0)\n",
        "        \n",
        "        # Embedding layer\n",
        "        embedded = self.embedding(input_seq.long()).view(-1,batch_size, self.embedding_size)\n",
        "        \n",
        "        # Encoder layers\n",
        "        encoder_hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        \n",
        "        if self.cell == 'LSTM':\n",
        "            encoder_cell = self.init_hidden(batch_size)\n",
        "            encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder_rnn(embedded, (encoder_hidden, encoder_cell))\n",
        "        else:\n",
        "            encoder_outputs, encoder_hidden = self.encoder_rnn(embedded, encoder_hidden)\n",
        "        if self.bidirectional:\n",
        "            encoder_hidden = torch.cat((encoder_hidden[-2,:,:], encoder_hidden[-1,:,:]), dim=1)\n",
        "        \n",
        "        return encoder_hidden, encoder_outputs\n",
        "\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, num_encoders, num_decoders, hidden_size, bidirectional=False,dropout=0.0, cell='GRU'):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoders = num_encoders\n",
        "        self.num_decoders = num_decoders\n",
        "        self.bidirectional = bidirectional\n",
        "        self.cell = cell\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        \n",
        "        if self.cell == 'GRU':\n",
        "            self.decoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_decoders,\n",
        "                                      bidirectional=bidirectional, dropout =dropout)\n",
        "        elif self.cell == 'LSTM':\n",
        "            self.decoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_decoders,\n",
        "                                       bidirectional=bidirectional,dropout =dropout)\n",
        "        else:\n",
        "            self.decoder_rnn = nn.RNN(embedding_size , hidden_size, num_layers=num_decoders,\n",
        "                                       bidirectional=bidirectional, dropout =dropout)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.decoder_fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "    # def forward(self, input_seq, encoder_hidden, encoder_outputs):\n",
        "    #     batch_size, max_len = input_seq.size()\n",
        "        \n",
        "        \n",
        "\n",
        "    #     decoder_input = (input_seq.T)[0]\n",
        "\n",
        "    #     print(decoder_input.shape)\n",
        "    #     # Embedding layer\n",
        "    #     embedded = self.embedding(decoder_input.long()).view(-1,batch_size, self.embedding_size)\n",
        "        \n",
        "        \n",
        "       \n",
        "    #     # Decoder layers\n",
        "    #     decoder_hidden = encoder_hidden[:self.num_decoders]\n",
        "\n",
        "    #     decoder_output = F.relu(embedded)\n",
        "\n",
        "        \n",
        "\n",
        "    #     decoder_output, decoder_hidden = self.decoder_rnn(embedded, decoder_hidden)\n",
        "    #     decoder_output = self.softmax(self.decoder_fc(decoder_output))\n",
        "    #     print(decoder_output.shape)\n",
        "    #     # # Handle different numbers of layers in the encoder and decoder\n",
        "    #     # if self.num_encoders != self.num_decoders:\n",
        "    #     #     if self.num_encoders < self.num_decoders:\n",
        "    #     #         # Copy all encoder hidden layers and then repeat the top layer\n",
        "    #     #         top_layer_hidden = encoder_hidden[-1].unsqueeze(0)\n",
        "    #     #         remaining_layers = self.num_decoders - self.num_encoders\n",
        "    #     #         extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "    #     #         decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "    #     #     else:\n",
        "    #     #         # Slice the hidden states of the encoder to match the decoder layers\n",
        "    #     #         decoder_hidden = encoder_hidden[-self.num_decoders:]\n",
        "    #     # else:\n",
        "    #     #     decoder_hidden = encoder_hidden\n",
        "    #     #     decoder_outputs[:,i,:] = decoder_output.squeeze(1)\n",
        "        \n",
        "    #     # decoder_outputs = self.softmax(self.decoder_fc(decoder_outputs))\n",
        "        \n",
        "    #     return decoder_output\n",
        "\n",
        "    def forward(self, input_seq, encoder_hidden, encoder_outputs):\n",
        "        batch_size = input_seq.shape[0]\n",
        "        \n",
        "        size_of_hidden = encoder_hidden.shape[0]\n",
        "        decoder_input = (input_seq)\n",
        "\n",
        "        decoder_input = decoder_input.unsqueeze(1)\n",
        "        \n",
        "        # Embedding layer\n",
        "        embedded = self.embedding(decoder_input.long()).view(-1,batch_size,self.embedding_size)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        \n",
        "        if(size_of_hidden>self.num_decoders):\n",
        "          decoder_hidden = encoder_hidden[self.num_encoders-self.num_decoders:]\n",
        "          \n",
        "        elif(size_of_hidden<self.num_decoders):\n",
        "          top = encoder_hidden[-1].unsqueeze(0)\n",
        "          extra = self.num_decoders-self.num_encoders\n",
        "          hiddenExtra =top.repeat(extra,1,1)\n",
        "          decoder_hidden =torch.cat((encoder_hidden,hiddenExtra),dim=0)\n",
        "\n",
        "        packed_output, decoder_hidden = self.decoder_rnn(embedded, decoder_hidden)\n",
        "       \n",
        "        # Project the output to the output size and apply softmax\n",
        "        decoder_output = self.decoder_fc(packed_output)\n",
        "        \n",
        "        decoder_output = F.log_softmax(decoder_output, dim=2)\n",
        "        \n",
        "        # Return the output tensor\n",
        "        return decoder_output,decoder_hidden\n",
        "\n",
        "def calculate_accuracy(output_tensor, target_tensor):\n",
        "    # Get the predicted word indices for each batch and sequence position\n",
        "    predicted_word_indices = output_tensor.argmax(dim=2)\n",
        "    \n",
        "    # Compare with target tensor to get the number of correct predictions\n",
        "    num_correct = torch.eq(predicted_word_indices, target_tensor).sum().item()\n",
        "    \n",
        "    # Calculate total number of predictions\n",
        "    total_predictions = target_tensor.numel()\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = num_correct / total_predictions\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Pwoce_8XKBhY"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get encoded data of perticular language\n",
        "\n",
        "data = EncodedData(\"mar\")    \n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "trainData = TensorDataset(data.train_xE, data.train_yE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwv002S2J8ie",
        "outputId": "7c256344-fa74-4dfa-eb3e-4cd38a68d5e5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7e__rzOqvHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learn_rate = 0.0001\n",
        "batch_size = 32\n",
        "hidden_size = 32\n",
        "embedding_size = 64\n",
        "num_encoder = 3\n",
        "num_decoder = 1\n",
        "cell_type = 'RNN'\n",
        "bidirectional = False\n",
        "dropout = 0\n",
        "nonlinearity = 'relu'\n",
        "teach_ratio = 0.5\n",
        "epochs = 10\n",
        "input_size = data.input_lang.n_chars\n",
        "output_size = data.output_lang.n_chars\n",
        "\n",
        "encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n",
        "decoder = DecoderRNN(output_size,embedding_size,num_encoder,num_decoder,hidden_size,bidirectional,dropout,cell_type)\n",
        "\n",
        "trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n",
        "\n",
        "validData = TensorDataset(data.val_xE,data.val_yE)\n",
        "validLoader = DataLoader(validData,batch_size=batch_size,shuffle=True) \n",
        "\n",
        "encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
        "decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
        "loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "for i in range(epochs):\n",
        " \n",
        "  running_loss = 0.0\n",
        "  train_correct = 0\n",
        "\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  for j,(train_x,train_y) in enumerate(trainLoader):\n",
        "      train_x = train_x.to(device)\n",
        "      train_y = train_y.to(device)\n",
        "\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "      \n",
        "      encoder_hidden,encoder_output = encoder(train_x)\n",
        "      \n",
        "      # # lets move to the decoder\n",
        "      \n",
        "\n",
        "      # print(encoder_output.shape)\n",
        "      # print(encoder_output.shape)\n",
        "      # Compute the loss and accuracy\n",
        "      \n",
        "      decoder_input =(train_y.T)[0]\n",
        "      decoder_hidden = encoder_hidden\n",
        "      pred_output={}\n",
        "      for k in range(train_y.shape[1]):\n",
        "\n",
        "      \n",
        "        decoder_output,decoder_hidden= decoder(decoder_input, encoder_hidden,encoder_output)\n",
        "        encoder_hidden = decoder_hidden\n",
        "        if(k==0):\n",
        "          pred_output = decoder_output\n",
        "        else:\n",
        "          pred_output = torch.cat([pred_output,decoder_output],dim=0)\n",
        "        \n",
        "\n",
        "        # Get the index of the maximum probability in each row\n",
        "        max_probs, indices = torch.max(decoder_output, dim=2)\n",
        "\n",
        "# Reshape the indices tensor to (16,) for easier indexing\n",
        "        indices = indices.view(batch_size)\n",
        "      # compare the predicted output with the true labels\n",
        "        decoder_input=indices\n",
        "\n",
        "      \n",
        "      loss = loss_fun(pred_output.view(-1, output_size), train_y.view(-1).long())\n",
        "      running_loss += loss.item()\n",
        "      # Compute the gradients and update the parameters\n",
        "      loss.backward()\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      # Compute the accuracy\n",
        "      preds = torch.argmax(pred_output, dim=2).T\n",
        "      train_correct += (preds == train_y).sum().item()\n",
        "      # Print the training progress\n",
        "      if j % 100 == 99:\n",
        "          avg_loss = running_loss / (batch_size * 100)\n",
        "          avg_acc = train_correct / (batch_size * 100 * train_y.size(1))\n",
        "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.5f}%'\n",
        "                .format(i+1, epochs, j+1, len(trainLoader), avg_loss, avg_acc*100))\n",
        "          running_loss = 0.0\n",
        "          train_correct = 0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "9cR7pPVjML2S",
        "outputId": "b2875e87-b895-4ed2-c720-1098262d3cd4"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/1600], Loss: 86.7294, Accuracy: 19.68324%\n",
            "Epoch [1/10], Step [200/1600], Loss: 69.4724, Accuracy: 50.66619%\n",
            "Epoch [1/10], Step [300/1600], Loss: 59.3548, Accuracy: 51.10227%\n",
            "Epoch [1/10], Step [400/1600], Loss: 55.8941, Accuracy: 51.14062%\n",
            "Epoch [1/10], Step [500/1600], Loss: 54.3532, Accuracy: 51.28693%\n",
            "Epoch [1/10], Step [600/1600], Loss: 53.7122, Accuracy: 51.05256%\n",
            "Epoch [1/10], Step [700/1600], Loss: 53.0453, Accuracy: 51.18324%\n",
            "Epoch [1/10], Step [800/1600], Loss: 52.8648, Accuracy: 51.02131%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-d39a21652c1d>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0;31m# Compute the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mstep_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "aVkoOG63MNSo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22fmCgJ59DO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YPOcnDlRYDRZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8bNxVuRa6ao"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QxHRRcegcuMv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CecJGVVp3-rJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XI-xax7_gPf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hRtX90Xy2gzH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-gb1qoV3_vu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UN8EqMnc4Vkw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFFGOYan5uR6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FvVi7lmazt52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOJE5dYriKu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.dropout import Dropout\n",
        "input_size = data.input_lang.n_chars\n",
        "output_size = data.output_lang.n_chars\n",
        "EMBEDDING_SIZE=16\n",
        "NUM_ENCODERS=2\n",
        "NUM_DECODERS=2\n",
        "HIDDEN_SIZE=32\n",
        "BIDIRECTIONAL=False\n",
        "BEAM_WIDTH = 1\n",
        "DROPOUT=0.0\n",
        "LEARNING_RATE=0.001\n",
        "PAD_TOKEN=0\n",
        "NUM_EPOCHS=1\n",
        "batch_size=2"
      ],
      "metadata": {
        "id": "TQapNbu06s8b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Se9DFLwy6Gub"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aoctb39aiaWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}