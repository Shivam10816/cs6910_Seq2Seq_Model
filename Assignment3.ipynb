{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivam10816/cs6910_assignment3/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvQ1-iNkFlwA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U95DxTfDMKru",
        "outputId": "f7f7545b-4edd-4b89-e00a-17ede8b5fb22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pwoce_8XKBhY"
      },
      "outputs": [],
      "source": [
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2index = {'#': 0, '$': 1, '^': 2}\n",
        "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
        "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
        "        self.n_chars = 3  # Count\n",
        "        self.data = {}\n",
        "        \n",
        "\n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            self.addChar(char)\n",
        "\n",
        "    def addChar(self, char):\n",
        "        if char not in self.char2index:\n",
        "            self.char2index[char] = self.n_chars\n",
        "            self.char2count[char] = 1\n",
        "            self.index2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "        else:\n",
        "            self.char2count[char] += 1\n",
        "\n",
        "\n",
        "\n",
        "class EncodedData:\n",
        "  def __init__(self,lang):\n",
        "    self.train_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_train.csv\", header = None)\n",
        "    self.val_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_valid.csv\", header = None)\n",
        "    self.test_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_test.csv\", header = None)\n",
        "\n",
        "    self.input_lang = Lang('eng')\n",
        "    self.output_lang = Lang(lang)\n",
        "\n",
        "    # add the words to the respective languages\n",
        "    for i in range(len(self.train_df)):\n",
        "        \n",
        "        self.input_lang.addWord(self.train_df[0][i])\n",
        "        self.output_lang.addWord(self.train_df[1][i])\n",
        "    \n",
        "    max_len_1,max_len_2 = self.max_word_lengths(self.train_df)\n",
        "    self.train_xE,self.train_yE = self.preprocessing(self.train_df,max_len_1,max_len_2)\n",
        "\n",
        "    max_len_1,max_len_2 = self.max_word_lengths(self.val_df)\n",
        "    self.val_xE,self.val_yE = self.preprocessing(self.val_df,max_len_1,max_len_2)\n",
        "\n",
        "    max_len_1,max_len_2 = self.max_word_lengths(self.test_df)\n",
        "    self.test_xE,self.test_yE = self.preprocessing(self.test_df,max_len_1,max_len_2)\n",
        "\n",
        "    print(type(self.train_xE))\n",
        "    \n",
        "  def max_word_lengths(self,df):\n",
        "    max_len_1 = df.iloc[:,0].str.len().max()\n",
        "    max_len_2 = df.iloc[:,1].str.len().max()\n",
        "    return max_len_1, max_len_2\n",
        "\n",
        "\n",
        "\n",
        "  def preprocessing(self,df,max_len_1,max_len_2):\n",
        "    \n",
        "    M1 = np.zeros((len(df),max_len_1+1))\n",
        "    M2 = np.zeros((len(df),max_len_2+2))\n",
        "\n",
        "    #print(M2.shape)\n",
        "    \n",
        "    # Encode column 1\n",
        "    col1 = df.iloc[:, 0].str.lower().str.split()\n",
        "\n",
        "    for i in range(len(col1)) :\n",
        "      word = col1[i][0]\n",
        "      # print(word,\" \" ,word[0],word[1])\n",
        "      for j in range(len(word)):\n",
        "        char =word[j]\n",
        "        if(self.input_lang.char2index.get(char) is not None):\n",
        "          M1[i][j]=self.input_lang.char2index.get(char)\n",
        "        else:\n",
        "          M1[i][j]=1\n",
        "    # print(col1)\n",
        "    #encoded_col1 = np.array([encode(words, dict1, max_len_1) for words in col1])\n",
        "    \n",
        "    # Encode column 2\n",
        "    col2 = df.iloc[:, 1].str.lower().str.split()\n",
        "    # print((col2[0]))\n",
        "    for i in range(len(col2)) :\n",
        "      word = col2[i][0]\n",
        "      # print(word,\" \" ,word[0],word[1])\n",
        "      M2[i][0]=2\n",
        "      for j in range(len(word)):\n",
        "        char =word[j]\n",
        "        if(self.output_lang.char2index.get(char) is not None):\n",
        "          M2[i][j+1]=self.output_lang.char2index.get(char)\n",
        "        else:\n",
        "          M2[i][j+1]=1\n",
        "      \n",
        "    \n",
        "    \n",
        "    return torch.from_numpy(M1),torch.from_numpy(M2)\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, num_encoders, hidden_size, bidirectional=False, cell='GRU',dropout=0.0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoders = num_encoders\n",
        "        self.bidirectional = bidirectional\n",
        "        self.cell = cell\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        if self.cell == 'RNN':\n",
        "            self.encoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_encoders,\n",
        "                                      bidirectional=bidirectional )\n",
        "        \n",
        "        elif self.cell == 'GRU':\n",
        "            self.encoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_encoders,\n",
        "                                      bidirectional=bidirectional)\n",
        "        else:\n",
        "            self.encoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_encoders,\n",
        "                                       bidirectional=bidirectional )\n",
        "    def init_hidden(self, batch_size):\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        if self.cell == 'LSTM':\n",
        "            return (torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device),\n",
        "                    torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device))\n",
        "        else:\n",
        "          return torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device)\n",
        "        \n",
        "    def forward(self, input_seq):\n",
        "        batch_size = input_seq.size(1)\n",
        "        \n",
        "        # Embedding layer\n",
        "        embedded = self.embedding(input_seq.long())\n",
        "        \n",
        "        embedded = self.dropout(embedded)\n",
        "        # Encoder layers\n",
        "        encoder_hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # print(encoder_hidden.shape)\n",
        "        if self.cell == 'LSTM':\n",
        "            (encoder_hidden,encoder_cell) = self.init_hidden(batch_size)\n",
        "            encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder_rnn(embedded, (encoder_hidden, encoder_cell))\n",
        "            encoder_hidden = (encoder_hidden,encoder_cell)\n",
        "        else:\n",
        "          \n",
        "          encoder_outputs, encoder_hidden = self.encoder_rnn(embedded, encoder_hidden)\n",
        "        \n",
        "        \n",
        "        return  encoder_outputs,encoder_hidden\n",
        "\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, num_encoders, num_decoders, hidden_size, dropout=0.0, cell='GRU'):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoders = num_encoders\n",
        "        self.num_decoders = num_decoders\n",
        "        \n",
        "        self.cell = cell\n",
        "        self.embedding_size = embedding_size\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.decoder_fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        \n",
        "\n",
        "        if self.cell == 'RNN':\n",
        "            self.decoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_decoders)\n",
        "        elif self.cell == 'GRU':\n",
        "            self.decoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_decoders)\n",
        "                                      \n",
        "        else :\n",
        "            self.decoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_decoders)                      \n",
        "                                     \n",
        "\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        batch_size = input_seq.shape[0]\n",
        "        \n",
        "\n",
        "        \n",
        "        decoder_input = (input_seq)\n",
        "\n",
        "        decoder_input = decoder_input.unsqueeze(1)\n",
        "        \n",
        "        # Embedding layer\n",
        "        embedded = self.embedding(decoder_input.long()).view(-1,batch_size,self.embedding_size)\n",
        "        embedded = self.dropout(embedded)\n",
        "        decoder_hidden = hidden\n",
        "\n",
        "        decoder_output , decoder_hidden = self.decoder_rnn(embedded, decoder_hidden)\n",
        "       \n",
        "        # Project the output to the output size and apply softmax\n",
        "\n",
        "        decoder_output = self.softmax(self.decoder_fc(decoder_output))\n",
        "        \n",
        "        # Return the output tensor\n",
        "        return decoder_output,decoder_hidden\n",
        "\n",
        "def count_exact_matches(pred, target):\n",
        "    \"\"\"\n",
        "    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n",
        "    preds: tensor of shape (batch_size, seq_len)\n",
        "    y: tensor of shape (batch_size, seq_len)\n",
        "    \"\"\"\n",
        "    pred = pred[:, 1:-1] # ignore first and last index of each row\n",
        "    target = target[:, 1:-1] # ignore first and last index of each row\n",
        "    count=0;\n",
        "    for i in range(pred.shape[0]):\n",
        "      flag = True\n",
        "      for j in range(target.shape[1]):\n",
        "        if(target[i][j]!=0 and target[i][j]!=pred[i][j]):\n",
        "          flag=False\n",
        "          break;\n",
        "         \n",
        "      if(flag):\n",
        "        count+=1;\n",
        "    \n",
        "    return count\n",
        "\n",
        "def evaluate(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "\n",
        "    running_loss =0\n",
        "    correct=0\n",
        "    total=0\n",
        "    Data = TensorDataset(X,Y)\n",
        "    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n",
        "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    with torch.no_grad():\n",
        "      for j,(x,y) in enumerate(Loader):\n",
        "        loss=0\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.transpose(0,1)\n",
        "        y = y.transpose(0,1)\n",
        "        encoder_output, encoder_hidden = encoder(x)\n",
        "        \n",
        "        if bidirectional:\n",
        "          if(cell_type==\"LSTM\"):\n",
        "            hidden,state = encoder_hidden\n",
        "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            hidden=torch.add(hidden[0],hidden[1])/2\n",
        "\n",
        "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            state=torch.add(state[0],state[1])/2\n",
        "            encoder_hidden =(hidden,state)\n",
        "\n",
        "          else:\n",
        "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
        "\n",
        "        # Initialize the decoder_hidden tensor\n",
        "          \n",
        "        \n",
        "        \n",
        "        decoder_input =(y)[0]\n",
        "        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n",
        "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
        "        \n",
        "        pred_output=torch.zeros(y.shape[0],batch_size,output_size)\n",
        "          \n",
        "\n",
        "        for k in range(1,y.shape[1]):\n",
        "\n",
        "          \n",
        "          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "          \n",
        "          pred_output[k-1]=decoder_output\n",
        "\n",
        "          # Get the index of the maximum probability in each row\n",
        "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
        "\n",
        "          \n",
        "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
        "          indices = indices.view(batch_size)\n",
        "          decoder_input=indices.clone()\n",
        "\n",
        "        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "          \n",
        "        pred_output[-1]=decoder_output\n",
        "        # print(pred_output.shape)\n",
        "        # print(train_y.shape)\n",
        "        \n",
        "        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n",
        "        y = y.reshape(-1)\n",
        "\n",
        "        pred_output = pred_output.to(device)\n",
        "        y =y.to(device)\n",
        "\n",
        "        loss = loss_fun(pred_output, y.long())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Compute the gradients and update the parameters\n",
        "        \n",
        "\n",
        "        # Compute the accuracy\n",
        "        preds = torch.argmax(pred_output, dim=1)\n",
        "\n",
        "        preds = preds.reshape(batch_size,-1)\n",
        "        y = y.reshape(batch_size,-1)\n",
        "        \n",
        "        # print(\"------------------Iter next--------------\")\n",
        "        # print(preds[:][0])\n",
        "        # print(train_y[0])\n",
        "        \n",
        "        # print(\"-------------------------PRED----------------------\")\n",
        "        # print(preds)\n",
        "        # print(\"-------------------------Train---------------------\")\n",
        "        # print(train_y)\n",
        "        correct += count_exact_matches(preds,y)\n",
        "          # Print the training progress\n",
        "          \n",
        "    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size))\n",
        "  \n",
        "    avg_acc = correct / X.shape[0]\n",
        "    print(' correct[{}/{}] Val_Loss: {:.4f}, val_Accuracy: {:.5f}%'\n",
        "          .format( correct,X.shape[0], avg_loss, avg_acc*100))\n",
        "            \n",
        "   \n",
        " \n",
        "\n",
        "def generateDecoderHidden(cell,num_encoder,num_decoder,encoder_hidden):\n",
        "    hidden={}\n",
        "    if(cell==\"LSTM\"):\n",
        "      \n",
        "      hx,state = (encoder_hidden)\n",
        "      if(num_encoder>num_decoder):\n",
        "        hx = hx[num_encoder-num_decoder:]\n",
        "        state = state[num_encoder-num_decoder:]\n",
        "      elif(num_encoder<num_decoder):\n",
        "        top = hx[-1].unsqueeze(0).clone()\n",
        "        extra = num_decoder-num_encoder\n",
        "        hiddenExtra =top.repeat(extra,1,1)\n",
        "        hx =torch.cat((hx,hiddenExtra),dim=0)\n",
        "      \n",
        "        stop = state[-1].unsqueeze(0).clone()\n",
        "        extra = num_decoder-num_encoder\n",
        "        stateExtra =top.repeat(extra,1,1)\n",
        "        state =torch.cat((state,stateExtra),dim=0)\n",
        "\n",
        "      hidden=(hx,state)\n",
        "    else :\n",
        "\n",
        "      hidden = encoder_hidden\n",
        "          \n",
        "      if(num_encoder>num_decoder):\n",
        "        hidden = encoder_hidden[num_encoder-num_decoder:]\n",
        "        \n",
        "      elif(num_encoder<num_decoder):\n",
        "        top = encoder_hidden[-1].unsqueeze(0).clone()\n",
        "        extra = num_decoder-num_encoder\n",
        "        hiddenExtra =top.repeat(extra,1,1)\n",
        "        hidden =torch.cat((encoder_hidden,hiddenExtra),dim=0)\n",
        "    return hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9deGoZpu4y25"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwv002S2J8ie",
        "outputId": "7c2cf849-f7ab-4e24-d6e7-6440acf2cfb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# get encoded data of perticular language\n",
        "\n",
        "data = EncodedData(\"hin\")    \n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7e__rzOqvHl"
      },
      "outputs": [],
      "source": [
        "def beam_search(encoder , decoder , test_x,test_y,lang_dict,max_size,batch_size,bidirectional,cell_type,beam_width):\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  \n",
        "  num_encoder = decoder.num_encoders\n",
        "  num_decoder = decoder.num_decoders\n",
        "  running_loss =0\n",
        "  correct=0\n",
        "  total=0\n",
        "  Data = TensorDataset(test_x,test_y)\n",
        "  Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n",
        "  for j,(test_x,test_y) in enumerate(Loader):\n",
        "\n",
        "      test_x = test_x.to(device)\n",
        "      test_x = test_x.transpose(0,1)\n",
        "\n",
        "      test_y = test_y.to(device)\n",
        "      test_y = test_y.transpose(0,1)\n",
        "\n",
        "      # Initialize the output token sequences for each input sequence in the batch\n",
        "      output_tokens = [[] for _ in range(batch_size)]\n",
        "\n",
        "      with torch.no_grad():\n",
        "        encode_output,encoder_hidden = encoder(test_x)\n",
        "\n",
        "      \n",
        "      # Initialize the beam search for each input sequence in the batch\n",
        "      beam = [[] for _ in range(batch_size)]\n",
        "      for i in range(batch_size):\n",
        "          beam[i].append((torch.tensor([[lang_dict['^']]], device=device), 0.0, None))\n",
        "\n",
        "      \n",
        "    \n",
        "\n",
        "      if bidirectional:\n",
        "          if(cell_type==\"LSTM\"):\n",
        "            hidden,state = encoder_hidden\n",
        "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            hidden=torch.add(hidden[0],hidden[1])/2\n",
        "\n",
        "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            state=torch.add(state[0],state[1])/2\n",
        "            encoder_hidden =(hidden,state)\n",
        "\n",
        "          else:\n",
        "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
        "      \n",
        "\n",
        "      hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
        "      \n",
        "      for t in range(max_size):\n",
        "        new_beam = [[] for _ in range(batch_size)]\n",
        "        \n",
        "        # Expand each sequence in the beam for each input sequence in the batch\n",
        "        for i in range(batch_size):\n",
        "            if len(beam[i]) == 0:\n",
        "                continue\n",
        "            \n",
        "            for seq, score, hidden in beam[i]:\n",
        "                # Get the last token in the sequence\n",
        "                token = seq[-1]\n",
        "                \n",
        "                # Decode the next token\n",
        "                output, hidden = decoder(token,hidden)\n",
        "\n",
        "                # print(output.shape)\n",
        "                output = torch.log(output.squeeze(0))\n",
        "                \n",
        "                \n",
        "                # Get the top k tokens and their scores\n",
        "                topk_scores, topk_tokens = output.topk(beam_width, dim=1)\n",
        "                topk_scores = topk_scores + score\n",
        "                \n",
        "                # print(\"topk score :-\", topk_scores.shape)\n",
        "                # print(\"topk tokens :-\", topk_tokens.shape)\n",
        "                if(seq.shape[0]==30):\n",
        "                  print(\"Predicted:-\", seq[:,0])\n",
        "                  print(\"Original :-\",test_y[:,i])\n",
        "\n",
        "                # print(\"Seq :-\", seq.shape)\n",
        "                # Create new sequences by appending each top k token to the end of the sequence\n",
        "                for j in range(beam_width):\n",
        "                    new_seq = torch.cat([seq, topk_tokens[0, j].unsqueeze(0).unsqueeze(0)])\n",
        "                    new_score = topk_scores[0,j].item()\n",
        "                    \n",
        "                    # Add the new sequence to the list of partial sequences for the corresponding input sequence\n",
        "                    new_beam[i].append((new_seq, new_score, hidden))\n",
        "        \n",
        "        # Select the top k sequences with the highest scores for each input sequence in the batch\n",
        "        for i in range(batch_size):\n",
        "            beam[i] = sorted(new_beam[i], key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "            \n",
        "            # If any sequences in the beam end with the <eos> token, remove them from the beam and add them to the output\n",
        "            for j in range(len(beam[i])):\n",
        "                if beam[i][j][0][-1] == lang_dict['#']:\n",
        "                    output_tokens[i].append([int(idx) for idx in beam[i][j][0].squeeze(0)])\n",
        "                    beam[i][j] = None\n",
        "            \n",
        "            beam[i] = [seq for seq in beam[i] if seq is not None]\n",
        "\n",
        "          \n",
        "\n",
        "      \n",
        "\n",
        "beam_search(encoder , decoder , data.test_xE,data.test_yE,data.output_lang.char2index,30,batch_size,bidirectional,cell_type,beam_width=3) \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cR7pPVjML2S"
      },
      "outputs": [],
      "source": [
        "learn_rate = 0.001\n",
        "batch_size = 16\n",
        "hidden_size = 128\n",
        "embedding_size = 128\n",
        "num_encoder = 3\n",
        "num_decoder = 3\n",
        "cell_type = 'LSTM'\n",
        "bidirectional =True\n",
        "dropout = 0.3\n",
        "teach_ratio = 0.5\n",
        "epochs = 1\n",
        "beam_width=0\n",
        "\n",
        "def trainRNNandGRU(data,cell_type=\"RNN\",embedding_size=64,num_encoder=2,num_decoders=2,hidden_size=32,batch_size=16,bidirectional=False,dropout=0.0,beam_width=0,epoch=10,learn_rate=0.001,teacher_ratio=0.0):\n",
        "  input_size = data.input_lang.n_chars\n",
        "  output_size = data.output_lang.n_chars\n",
        "  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n",
        "  decoder = DecoderRNN(output_size,embedding_size,num_encoder,num_decoder,hidden_size,dropout,cell_type)\n",
        "\n",
        "  trainData = TensorDataset(data.train_xE, data.train_yE)\n",
        "  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n",
        "\n",
        "\n",
        "\n",
        "  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
        "  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
        "  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "  encoder.to(device)\n",
        "  decoder.to(device)\n",
        "\n",
        "  for i in range(epochs):\n",
        "  \n",
        "    running_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    for j,(train_x,train_y) in enumerate(trainLoader):\n",
        "        loss=0\n",
        "        train_x = train_x.to(device)\n",
        "        train_y = train_y.to(device)\n",
        "\n",
        "        train_x = train_x.transpose(0, 1)\n",
        "        train_y = train_y.transpose(0, 1)\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(train_x)\n",
        "        \n",
        "        # print(encoder_hidden.shape)\n",
        "        # # lets move to the decoder\n",
        "        # if(bidirectional):\n",
        "        #     split_tensor= torch.split(encoder_output, hidden_size, dim=-1)\n",
        "        #     encoder_output=torch.add(split_tensor[0],split_tensor[1])/2\n",
        "        \n",
        "\n",
        "        \n",
        "        if bidirectional:\n",
        "          if(cell_type==\"LSTM\"):\n",
        "            hidden,state = encoder_hidden\n",
        "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            hidden=torch.add(hidden[0],hidden[1])/2\n",
        "\n",
        "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            state=torch.add(state[0],state[1])/2\n",
        "            encoder_hidden =(hidden,state)\n",
        "\n",
        "          else:\n",
        "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
        "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
        "\n",
        "        # Initialize the decoder_hidden tensor\n",
        "          \n",
        "        # Compute the loss and accuracy\n",
        "        \n",
        "        decoder_input =(train_y)[0]\n",
        "        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n",
        "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
        "        \n",
        "        pred_output=torch.zeros(train_y.shape[0],batch_size,output_size)\n",
        "          \n",
        "        \n",
        "        for k in range(1,train_y.shape[0]):\n",
        "\n",
        "          \n",
        "          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "          \n",
        "          pred_output[k-1]=decoder_output\n",
        "\n",
        "          # Get the index of the maximum probability in each row\n",
        "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
        "\n",
        "          # print(indices)\n",
        "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
        "          indices = indices.view(batch_size)\n",
        "          \n",
        "          if((random.random()<teach_ratio)):\n",
        "            decoder_input=(train_y)[k]\n",
        "          else:\n",
        "            decoder_input=indices.clone()\n",
        "\n",
        "        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "          \n",
        "        pred_output[-1]=decoder_output\n",
        "        # print(pred_output.shape)\n",
        "        # print(train_y.shape)\n",
        "        # print(pred_output.shape)\n",
        "        # print(train_y.shape)\n",
        "\n",
        "        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n",
        "        train_y = train_y.reshape(-1)\n",
        "\n",
        "        pred_output = pred_output.to(device)\n",
        "        train_y = train_y.to(device)\n",
        "        loss = loss_fun(pred_output, train_y.long())\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Compute the gradients and update the parameters\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        # Compute the accuracy\n",
        "        # print(pred_output.shape)\n",
        "        preds = torch.argmax(pred_output, dim=1)\n",
        "        # print(\"------------------Iter next--------------\")\n",
        "        # print(preds[:][0])\n",
        "        # print(train_y[0])\n",
        "        # print(preds.shape)\n",
        "        # print(train_y.shape)\n",
        "        # print(\"-------------------------PRED----------------------\")\n",
        "        # print(preds)\n",
        "        # print(\"-------------------------Train---------------------\")\n",
        "        # print(train_y)\n",
        "        \n",
        "        # Print the training progress\n",
        "        if j % 100 == 99:\n",
        "            avg_loss = running_loss / (batch_size * 100)\n",
        "            \n",
        "            print('Epoch [{}/{}], Step [{}/{}], Train_Loss: {:.4f}'\n",
        "                  .format(i+1, epochs, j+1, len(trainLoader), avg_loss))\n",
        "            # evaluate(data.val_xE,data.val_yE,encoder,decoder,device,output_size,batch_size,cell_type)\n",
        "            running_loss = 0.0\n",
        "            train_correct = 0\n",
        "            \n",
        "    evaluate(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
        "\n",
        "  return encoder ,decoder\n",
        "\n",
        "\n",
        "encoder,decoder=trainRNNandGRU(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epochs,learn_rate,teach_ratio)\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aVkoOG63MNSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4db96e9-380d-4c3f-c094-926329008d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " correct[1618/4096] Val_Loss: 39.4536, val_Accuracy: 39.50195%\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1FSM2NTLCeC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_decoder,cell_type, dropout=0.0):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "\n",
        "        # Define the input size, hidden size, output size, and number of layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Define the embedding layer\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "\n",
        "        # Define the attention mechanism\n",
        "        self.attention = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
        "        self.context_vector = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        # Define the output layer\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        #define softmax\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        if cell_type ==\"RNN\" :\n",
        "          # Define the RNN layer\n",
        "          self.decoder_rnn =  nn.RNN(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n",
        "        elif cell_type == \"GRU\":\n",
        "          self.decoder_rnn =  nn.GRU(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n",
        "        else :\n",
        "          self.decoder_rnn =  nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # Compute the attention scores\n",
        "        batch_size = input.shape[1]\n",
        "        seq_len = input.shape[0]\n",
        "       \n",
        "        \n",
        "\n",
        "        return output, hidden, attention_weights\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22fmCgJ59DO2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPOcnDlRYDRZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8bNxVuRa6ao"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxHRRcegcuMv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CecJGVVp3-rJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI-xax7_gPf2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRtX90Xy2gzH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-gb1qoV3_vu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN8EqMnc4Vkw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFFGOYan5uR6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvVi7lmazt52"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOJE5dYriKu6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQapNbu06s8b"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.dropout import Dropout\n",
        "input_size = data.input_lang.n_chars\n",
        "output_size = data.output_lang.n_chars\n",
        "EMBEDDING_SIZE=16\n",
        "NUM_ENCODERS=2\n",
        "NUM_DECODERS=2\n",
        "HIDDEN_SIZE=32\n",
        "BIDIRECTIONAL=False\n",
        "BEAM_WIDTH = 1\n",
        "DROPOUT=0.0\n",
        "LEARNING_RATE=0.001\n",
        "PAD_TOKEN=0\n",
        "NUM_EPOCHS=1\n",
        "batch_size=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se9DFLwy6Gub"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoctb39aiaWn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "16d5-SjPO8eM9xVBs72Lf4HY2McPKRjcT",
      "authorship_tag": "ABX9TyNiTzM+Tn4ml2Wu9nTvTOeO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}